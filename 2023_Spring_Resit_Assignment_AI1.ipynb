{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "#University of Stirling - Spring 2023\n",
        "\n",
        "## ITNPAI1 - Deep Learning for Vision and NLP (2022/3)\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "4i5afvUbhmGo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resit Assignment Summary\n",
        "\n",
        "In this activity, you are required to apply the knowledge acquired in this module through the design and development of a complete project for deep learning-based image pattern recognition in an application to be defined by yourself. For this, you will need to perform the following steps:\n",
        "\n",
        "1. [Problem definition](#scrollTo=hglJVRRslqMn)\n",
        "2. [GitHub repository](#scrollTo=ecxDhkV9qmUf)\n",
        "3. [Dataset](#scrollTo=qEgFzxmWrGA9)\n",
        "4. [Dataloader](#scrollTo=EDd6lLwlx4un)\n",
        "5. [Proposed solution](#scrollTo=ScTrpUW8zOp4)\n",
        "6. [Experimental tests and evaluations](#scrollTo=3RBW58of0ZDo)\n",
        "7. [Quiz and Report](#scrollTo=ws14iV4Dp_vf)\n"
      ],
      "metadata": {
        "id": "cJZF464wk6Xh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# 1. **Problem definition**\n",
        "\n",
        "\n",
        "You must choose a computer vision task (classification, detection or semantic segmentation) to be modeled from images collected from two different geographic locations (A and B). It can be different neighbourhoods in the same city.\n",
        " - The standard project recommendation is to focus on recognizing cars or trees, which are easier to identify and annotate. Other objects or phenomena can be adopted, but are subject to prior approval by the module instructor (Jefersson A. dos Santos). **It is not allowed to assemble datasets containing people. Other sensitive patterns, such as license plates, must be properly hidden.**\n",
        "\n",
        "[top](#scrollTo=4i5afvUbhmGo)\n"
      ],
      "metadata": {
        "id": "hglJVRRslqMn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 2. **GitHub repository**\n",
        "\n",
        "Give your project a name, create a private [GitHub repository](https://github.com/) with the name [Module Code] + [Project Name] and give access to the module instructors. Create a cover page with a description of your project. This empty notebook must be uploaded in the repository as well as the created dataset. The checkpoint date to perform this task will be two weeks after the publication of this notebook.\n",
        "This notebook should be updated and committed to the repository according to the checkpoint dates.\n",
        "The repository's update history will be used as a criterion for monitoring and evaluating the work.\n",
        "**Check the videos provided in the extra section on Canvas for more details on how to create your GitHub repository.**\n",
        "\n",
        "[top](#scrollTo=4i5afvUbhmGo)"
      ],
      "metadata": {
        "id": "ecxDhkV9qmUf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/Qurat5/ITNPA1-Deep-Learning-based-Car-Detection-from-Google-Earth-Images-using-YOLOv7-and-PyTorch.git"
      ],
      "metadata": {
        "id": "0FN9j1TPbEh6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 3. **Dataset creation**\n",
        "\n",
        "You must collect a minimum of **200 positive samples** from the study objects for each location (A and B).\n",
        "Note that, depending on the task being solved, it will also be necessary to:\n",
        "\n",
        "   (i) collect more samples - negative ones, for instance;\n",
        "\n",
        "   (ii) annotating each image, delineating objects or creating bounding boxes. Planning and executing this correctly is important to ensure effective training of deep learning-based models.\n",
        "\n",
        "Your dataset can be assembled from one or more of the following ways:\n",
        "\n",
        "  - *M1* - Pictures taken by yourself on site (street view from cities A and B), with attention to anonymization issues (if it is the case). It is not allowed to assemble datasets containing people. Other sensitive patterns, such as license plates, must be properly hidden.\n",
        "\n",
        "  - *M2* - Aerial satellite/drone images obtained from GIS and remote sensing platforms or public repositories. Be careful with unusual file formats that may be challenging to manipulate using basic image processing libraries. We recommend keeping or converting the images to jpg or png.\n",
        "\n",
        "  - *M3* - Pictures taken from other public available datasets. Remember you are not allowed to use datasets containing people or other sensitive patterns/objects.\n",
        "\n",
        "  - *M4* - Images crawled from the internet as a whole (social networks, webpages, etc), with special attention to use and copyrights.\n",
        "\n",
        "  - *M5* - Textual and metadata you may need in your project, with special attention to use and copyrights (as always!).\n",
        "\n",
        "**Important:** If you collect the images on your own or from aerial imagery repositories, it will be necessary to keep the geographic coordinates. If you collect from specific websites, please retain the source links. This information should be placed in a .csv file and made available along with the final dataset.\n",
        "\n",
        "[top](#scrollTo=4i5afvUbhmGo)"
      ],
      "metadata": {
        "id": "qEgFzxmWrGA9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# 4. **Dataloader**\n",
        "\n",
        "Here you are required to implement all the code related to pre-processing, cleaning, de-noising and preparing the input images and metadata according to the necessary data structures as input to your pattern recognition module. We recommend using [PyTorch](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html) or [Tensorflow (with Keras)](https://keras.io/getting_started/intro_to_keras_for_engineers/) as a base, but you are free to use any library or platform as long as it is well justified in the [final report](#scrollTo=ws14iV4Dp_vf).\n",
        "\n",
        "[top](scrollTo=4i5afvUbhmGo)"
      ],
      "metadata": {
        "id": "EDd6lLwlx4un"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***This project involves object detection using YOLOv7 algorithm.***"
      ],
      "metadata": {
        "id": "vglXoK-dVGhV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your dataloader code here. Create more code cells if you find it necessary\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def preprocess(img, input_shape, letter_box=True):\n",
        "    if letter_box:\n",
        "        img_h, img_w, _ = img.shape\n",
        "        new_h, new_w = input_shape[0], input_shape[1]\n",
        "        offset_h, offset_w = 0, 0\n",
        "        if (new_w / img_w) <= (new_h / img_h):\n",
        "            new_h = int(img_h * new_w / img_w)\n",
        "            offset_h = (input_shape[0] - new_h) // 2\n",
        "        else:\n",
        "            new_w = int(img_w * new_h / img_h)\n",
        "            offset_w = (input_shape[1] - new_w) // 2\n",
        "        resized = cv2.resize(img, (new_w, new_h))\n",
        "        img = np.full((input_shape[0], input_shape[1], 3), 127, dtype=np.uint8)\n",
        "        img[offset_h:(offset_h + new_h), offset_w:(offset_w + new_w), :] = resized\n",
        "    else:\n",
        "        img = cv2.resize(img, (input_shape[1], input_shape[0]))\n",
        "\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = img.transpose((2, 0, 1)).astype(np.float32)\n",
        "    img /= 255.0\n",
        "    return img\n",
        "\n",
        "# Folder and input shape configuration\n",
        "image_folder = \"home/yolov7/train\"\n",
        "input_shape = (416, 416)\n",
        "\n",
        "# Iterate over image files in the folder\n",
        "for filename in os.listdir(image_folder):\n",
        "    if filename.endswith(\".jpg\"):\n",
        "        image_path = os.path.join(image_folder, filename)\n",
        "\n",
        "        # Load and preprocess the image\n",
        "        image = cv2.imread(image_path)\n",
        "        preprocessed_image = preprocess(image, input_shape)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RaPd82NmyNCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# 5. **Proposed solution**\n",
        "\n",
        "This is where you should implement most of the code for your solution. Write the routines for training and predicting the models and any necessary intermediate steps. Post-processing functions must also be implemented here.\n",
        "\n",
        "  - Use good programming practices, modularizing and adequately commenting on your code. Code quality will be considered in the final assessment.\n",
        "Again, we recommend using [PyTorch](https://pytorch.org/tutorials/beginner/introyt.html), but you are free to use any library or platform. You just need to justify that in the [final report](#scrollTo=ws14iV4Dp_vf).\n",
        "\n",
        "  - You can use pre-trained models as backbones or any code available on the web as a basis, but they must be correctly credited and referenced both in this notebook and in the final report. Cite the source link repository and explicitly cite the authors of it.\n",
        "If you changed existing code, make it clear what the changes were.\n",
        "Make it clear where your own code starts and where it ends. Note that the originality percentage of the code will be considered in the evaluation, so use external codes wisely and sparingly. **Missconduct alert:** remember that there are many tools that compare existing source code and that it is relatively easy to identify authorship. So, be careful and fair by always properly thanking the authors if you use external code.\n",
        "\n",
        "[top](#scrollTo=4i5afvUbhmGo)"
      ],
      "metadata": {
        "id": "ScTrpUW8zOp4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "l-6OrI2X6F1K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import logging\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "from copy import deepcopy\n",
        "from pathlib import Path\n",
        "from threading import Thread\n",
        "\n",
        "import numpy as np\n",
        "import torch.distributed as dist\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "import torch.utils.data\n",
        "import yaml\n",
        "from torch.cuda import amp\n",
        "from torch.nn.parallel import DistributedDataParallel as DDP\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from tqdm import tqdm\n",
        "\n",
        "import test  # import test.py to get mAP after each epoch\n",
        "from models.experimental import attempt_load\n",
        "from models.yolo import Model\n",
        "from utils.autoanchor import check_anchors\n",
        "from utils.datasets import create_dataloader\n",
        "from utils.general import labels_to_class_weights, increment_path, labels_to_image_weights, init_seeds, \\\n",
        "    fitness, strip_optimizer, get_latest_run, check_dataset, check_file, check_git_status, check_img_size, \\\n",
        "    check_requirements, print_mutation, set_logging, one_cycle, colorstr\n",
        "from utils.google_utils import attempt_download\n",
        "from utils.loss import ComputeLoss, ComputeLossOTA\n",
        "from utils.plots import plot_images, plot_labels, plot_results, plot_evolution\n",
        "from utils.torch_utils import ModelEMA, select_device, intersect_dicts, torch_distributed_zero_first, is_parallel\n",
        "from utils.wandb_logging.wandb_utils import WandbLogger, check_wandb_resume\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "def train(hyp, opt, device, tb_writer=None):\n",
        "    logger.info(colorstr('hyperparameters: ') + ', '.join(f'{k}={v}' for k, v in hyp.items()))\n",
        "    save_dir, epochs, batch_size, total_batch_size, weights, rank, freeze = \\\n",
        "        Path(opt.save_dir), opt.epochs, opt.batch_size, opt.total_batch_size, opt.weights, opt.global_rank, opt.freeze\n",
        "\n",
        "    # Directories\n",
        "    wdir = save_dir / 'weights'\n",
        "    wdir.mkdir(parents=True, exist_ok=True)  # make dir\n",
        "    last = wdir / 'last.pt'\n",
        "    best = wdir / 'best.pt'\n",
        "    results_file = save_dir / 'results.txt'\n",
        "\n",
        "    # Save run settings\n",
        "    with open(save_dir / 'hyp.yaml', 'w') as f:\n",
        "        yaml.dump(hyp, f, sort_keys=False)\n",
        "    with open(save_dir / 'opt.yaml', 'w') as f:\n",
        "        yaml.dump(vars(opt), f, sort_keys=False)\n",
        "\n",
        "    # Configure\n",
        "    plots = not opt.evolve  # create plots\n",
        "    cuda = device.type != 'cpu'\n",
        "    init_seeds(2 + rank)\n",
        "    with open(opt.data) as f:\n",
        "        data_dict = yaml.load(f, Loader=yaml.SafeLoader)  # data dict\n",
        "    is_coco = opt.data.endswith('coco.yaml')\n",
        "\n",
        "    # Logging- Doing this before checking the dataset. Might update data_dict\n",
        "    loggers = {'wandb': None}  # loggers dict\n",
        "    if rank in [-1, 0]:\n",
        "        opt.hyp = hyp  # add hyperparameters\n",
        "        run_id = torch.load(weights, map_location=device).get('wandb_id') if weights.endswith('.pt') and os.path.isfile(weights) else None\n",
        "        wandb_logger = WandbLogger(opt, Path(opt.save_dir).stem, run_id, data_dict)\n",
        "        loggers['wandb'] = wandb_logger.wandb\n",
        "        data_dict = wandb_logger.data_dict\n",
        "        if wandb_logger.wandb:\n",
        "            weights, epochs, hyp = opt.weights, opt.epochs, opt.hyp  # WandbLogger might update weights, epochs if resuming\n",
        "\n",
        "    nc = 1 if opt.single_cls else int(data_dict['nc'])  # number of classes\n",
        "    names = ['item'] if opt.single_cls and len(data_dict['names']) != 1 else data_dict['names']  # class names\n",
        "    assert len(names) == nc, '%g names found for nc=%g dataset in %s' % (len(names), nc, opt.data)  # check\n",
        "\n",
        "    # Model\n",
        "    pretrained = weights.endswith('.pt')\n",
        "    if pretrained:\n",
        "        with torch_distributed_zero_first(rank):\n",
        "            attempt_download(weights)  # download if not found locally\n",
        "        ckpt = torch.load(weights, map_location=device)  # load checkpoint\n",
        "        model = Model(opt.cfg or ckpt['model'].yaml, ch=3, nc=nc, anchors=hyp.get('anchors')).to(device)  # create\n",
        "        exclude = ['anchor'] if (opt.cfg or hyp.get('anchors')) and not opt.resume else []  # exclude keys\n",
        "        state_dict = ckpt['model'].float().state_dict()  # to FP32\n",
        "        state_dict = intersect_dicts(state_dict, model.state_dict(), exclude=exclude)  # intersect\n",
        "        model.load_state_dict(state_dict, strict=False)  # load\n",
        "        logger.info('Transferred %g/%g items from %s' % (len(state_dict), len(model.state_dict()), weights))  # report\n",
        "    else:\n",
        "        model = Model(opt.cfg, ch=3, nc=nc, anchors=hyp.get('anchors')).to(device)  # create\n",
        "    with torch_distributed_zero_first(rank):\n",
        "        check_dataset(data_dict)  # check\n",
        "    train_path = data_dict['train']\n",
        "    test_path = data_dict['val']\n",
        "\n",
        "    # Freeze\n",
        "    freeze = [f'model.{x}.' for x in (freeze if len(freeze) > 1 else range(freeze[0]))]  # parameter names to freeze (full or partial)\n",
        "    for k, v in model.named_parameters():\n",
        "        v.requires_grad = True  # train all layers\n",
        "        if any(x in k for x in freeze):\n",
        "            print('freezing %s' % k)\n",
        "            v.requires_grad = False\n",
        "\n",
        "    # Optimizer\n",
        "    nbs = 64  # nominal batch size\n",
        "    accumulate = max(round(nbs / total_batch_size), 1)  # accumulate loss before optimizing\n",
        "    hyp['weight_decay'] *= total_batch_size * accumulate / nbs  # scale weight_decay\n",
        "    logger.info(f\"Scaled weight_decay = {hyp['weight_decay']}\")\n",
        "\n",
        "    pg0, pg1, pg2 = [], [], []  # optimizer parameter groups\n",
        "    for k, v in model.named_modules():\n",
        "        if hasattr(v, 'bias') and isinstance(v.bias, nn.Parameter):\n",
        "            pg2.append(v.bias)  # biases\n",
        "        if isinstance(v, nn.BatchNorm2d):\n",
        "            pg0.append(v.weight)  # no decay\n",
        "        elif hasattr(v, 'weight') and isinstance(v.weight, nn.Parameter):\n",
        "            pg1.append(v.weight)  # apply decay\n",
        "        if hasattr(v, 'im'):\n",
        "            if hasattr(v.im, 'implicit'):\n",
        "                pg0.append(v.im.implicit)\n",
        "            else:\n",
        "                for iv in v.im:\n",
        "                    pg0.append(iv.implicit)\n",
        "        if hasattr(v, 'imc'):\n",
        "            if hasattr(v.imc, 'implicit'):\n",
        "                pg0.append(v.imc.implicit)\n",
        "            else:\n",
        "                for iv in v.imc:\n",
        "                    pg0.append(iv.implicit)\n",
        "        if hasattr(v, 'imb'):\n",
        "            if hasattr(v.imb, 'implicit'):\n",
        "                pg0.append(v.imb.implicit)\n",
        "            else:\n",
        "                for iv in v.imb:\n",
        "                    pg0.append(iv.implicit)\n",
        "        if hasattr(v, 'imo'):\n",
        "            if hasattr(v.imo, 'implicit'):\n",
        "                pg0.append(v.imo.implicit)\n",
        "            else:\n",
        "                for iv in v.imo:\n",
        "                    pg0.append(iv.implicit)\n",
        "        if hasattr(v, 'ia'):\n",
        "            if hasattr(v.ia, 'implicit'):\n",
        "                pg0.append(v.ia.implicit)\n",
        "            else:\n",
        "                for iv in v.ia:\n",
        "                    pg0.append(iv.implicit)\n",
        "        if hasattr(v, 'attn'):\n",
        "            if hasattr(v.attn, 'logit_scale'):\n",
        "                pg0.append(v.attn.logit_scale)\n",
        "            if hasattr(v.attn, 'q_bias'):\n",
        "                pg0.append(v.attn.q_bias)\n",
        "            if hasattr(v.attn, 'v_bias'):\n",
        "                pg0.append(v.attn.v_bias)\n",
        "            if hasattr(v.attn, 'relative_position_bias_table'):\n",
        "                pg0.append(v.attn.relative_position_bias_table)\n",
        "        if hasattr(v, 'rbr_dense'):\n",
        "            if hasattr(v.rbr_dense, 'weight_rbr_origin'):\n",
        "                pg0.append(v.rbr_dense.weight_rbr_origin)\n",
        "            if hasattr(v.rbr_dense, 'weight_rbr_avg_conv'):\n",
        "                pg0.append(v.rbr_dense.weight_rbr_avg_conv)\n",
        "            if hasattr(v.rbr_dense, 'weight_rbr_pfir_conv'):\n",
        "                pg0.append(v.rbr_dense.weight_rbr_pfir_conv)\n",
        "            if hasattr(v.rbr_dense, 'weight_rbr_1x1_kxk_idconv1'):\n",
        "                pg0.append(v.rbr_dense.weight_rbr_1x1_kxk_idconv1)\n",
        "            if hasattr(v.rbr_dense, 'weight_rbr_1x1_kxk_conv2'):\n",
        "                pg0.append(v.rbr_dense.weight_rbr_1x1_kxk_conv2)\n",
        "            if hasattr(v.rbr_dense, 'weight_rbr_gconv_dw'):\n",
        "                pg0.append(v.rbr_dense.weight_rbr_gconv_dw)\n",
        "            if hasattr(v.rbr_dense, 'weight_rbr_gconv_pw'):\n",
        "                pg0.append(v.rbr_dense.weight_rbr_gconv_pw)\n",
        "            if hasattr(v.rbr_dense, 'vector'):\n",
        "                pg0.append(v.rbr_dense.vector)\n",
        "\n",
        "    if opt.adam:\n",
        "        optimizer = optim.Adam(pg0, lr=hyp['lr0'], betas=(hyp['momentum'], 0.999))  # adjust beta1 to momentum\n",
        "    else:\n",
        "        optimizer = optim.SGD(pg0, lr=hyp['lr0'], momentum=hyp['momentum'], nesterov=True)\n",
        "\n",
        "    optimizer.add_param_group({'params': pg1, 'weight_decay': hyp['weight_decay']})  # add pg1 with weight_decay\n",
        "    optimizer.add_param_group({'params': pg2})  # add pg2 (biases)\n",
        "    logger.info('Optimizer groups: %g .bias, %g conv.weight, %g other' % (len(pg2), len(pg1), len(pg0)))\n",
        "    del pg0, pg1, pg2\n",
        "\n",
        "    # Scheduler https://arxiv.org/pdf/1812.01187.pdf\n",
        "    # https://pytorch.org/docs/stable/_modules/torch/optim/lr_scheduler.html#OneCycleLR\n",
        "    if opt.linear_lr:\n",
        "        lf = lambda x: (1 - x / (epochs - 1)) * (1.0 - hyp['lrf']) + hyp['lrf']  # linear\n",
        "    else:\n",
        "        lf = one_cycle(1, hyp['lrf'], epochs)  # cosine 1->hyp['lrf']\n",
        "    scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lf)\n",
        "    # plot_lr_scheduler(optimizer, scheduler, epochs)\n",
        "\n",
        "    # EMA\n",
        "    ema = ModelEMA(model) if rank in [-1, 0] else None\n",
        "\n",
        "    # Resume\n",
        "    start_epoch, best_fitness = 0, 0.0\n",
        "    if pretrained:\n",
        "        # Optimizer\n",
        "        if ckpt['optimizer'] is not None:\n",
        "            optimizer.load_state_dict(ckpt['optimizer'])\n",
        "            best_fitness = ckpt['best_fitness']\n",
        "\n",
        "        # EMA\n",
        "        if ema and ckpt.get('ema'):\n",
        "            ema.ema.load_state_dict(ckpt['ema'].float().state_dict())\n",
        "            ema.updates = ckpt['updates']\n",
        "\n",
        "        # Results\n",
        "        if ckpt.get('training_results') is not None:\n",
        "            results_file.write_text(ckpt['training_results'])  # write results.txt\n",
        "\n",
        "        # Epochs\n",
        "        start_epoch = ckpt['epoch'] + 1\n",
        "        if opt.resume:\n",
        "            assert start_epoch > 0, '%s training to %g epochs is finished, nothing to resume.' % (weights, epochs)\n",
        "        if epochs < start_epoch:\n",
        "            logger.info('%s has been trained for %g epochs. Fine-tuning for %g additional epochs.' %\n",
        "                        (weights, ckpt['epoch'], epochs))\n",
        "            epochs += ckpt['epoch']  # finetune additional epochs\n",
        "\n",
        "        del ckpt, state_dict\n",
        "\n",
        "    # Image sizes\n",
        "    gs = max(int(model.stride.max()), 32)  # grid size (max stride)\n",
        "    nl = model.model[-1].nl  # number of detection layers (used for scaling hyp['obj'])\n",
        "    imgsz, imgsz_test = [check_img_size(x, gs) for x in opt.img_size]  # verify imgsz are gs-multiples\n",
        "\n",
        "    # DP mode\n",
        "    if cuda and rank == -1 and torch.cuda.device_count() > 1:\n",
        "        model = torch.nn.DataParallel(model)\n",
        "\n",
        "    # SyncBatchNorm\n",
        "    if opt.sync_bn and cuda and rank != -1:\n",
        "        model = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model).to(device)\n",
        "        logger.info('Using SyncBatchNorm()')\n",
        "\n",
        "    # Trainloader\n",
        "    dataloader, dataset = create_dataloader(train_path, imgsz, batch_size, gs, opt,\n",
        "                                            hyp=hyp, augment=True, cache=opt.cache_images, rect=opt.rect, rank=rank,\n",
        "                                            world_size=opt.world_size, workers=opt.workers,\n",
        "                                            image_weights=opt.image_weights, quad=opt.quad, prefix=colorstr('train: '))\n",
        "    mlc = np.concatenate(dataset.labels, 0)[:, 0].max()  # max label class\n",
        "    nb = len(dataloader)  # number of batches\n",
        "    assert mlc < nc, 'Label class %g exceeds nc=%g in %s. Possible class labels are 0-%g' % (mlc, nc, opt.data, nc - 1)\n",
        "\n",
        "    # Process 0\n",
        "    if rank in [-1, 0]:\n",
        "        testloader = create_dataloader(test_path, imgsz_test, batch_size * 2, gs, opt,  # testloader\n",
        "                                       hyp=hyp, cache=opt.cache_images and not opt.notest, rect=True, rank=-1,\n",
        "                                       world_size=opt.world_size, workers=opt.workers,\n",
        "                                       pad=0.5, prefix=colorstr('val: '))[0]\n",
        "\n",
        "        if not opt.resume:\n",
        "            labels = np.concatenate(dataset.labels, 0)\n",
        "            c = torch.tensor(labels[:, 0])  # classes\n",
        "            # cf = torch.bincount(c.long(), minlength=nc) + 1.  # frequency\n",
        "            # model._initialize_biases(cf.to(device))\n",
        "            if plots:\n",
        "                #plot_labels(labels, names, save_dir, loggers)\n",
        "                if tb_writer:\n",
        "                    tb_writer.add_histogram('classes', c, 0)\n",
        "\n",
        "            # Anchors\n",
        "            if not opt.noautoanchor:\n",
        "                check_anchors(dataset, model=model, thr=hyp['anchor_t'], imgsz=imgsz)\n",
        "            model.half().float()  # pre-reduce anchor precision\n",
        "\n",
        "    # DDP mode\n",
        "    if cuda and rank != -1:\n",
        "        model = DDP(model, device_ids=[opt.local_rank], output_device=opt.local_rank,\n",
        "                    # nn.MultiheadAttention incompatibility with DDP https://github.com/pytorch/pytorch/issues/26698\n",
        "                    find_unused_parameters=any(isinstance(layer, nn.MultiheadAttention) for layer in model.modules()))\n",
        "\n",
        "    # Model parameters\n",
        "    hyp['box'] *= 3. / nl  # scale to layers\n",
        "    hyp['cls'] *= nc / 80. * 3. / nl  # scale to classes and layers\n",
        "    hyp['obj'] *= (imgsz / 640) ** 2 * 3. / nl  # scale to image size and layers\n",
        "    hyp['label_smoothing'] = opt.label_smoothing\n",
        "    model.nc = nc  # attach number of classes to model\n",
        "    model.hyp = hyp  # attach hyperparameters to model\n",
        "    model.gr = 1.0  # iou loss ratio (obj_loss = 1.0 or iou)\n",
        "    model.class_weights = labels_to_class_weights(dataset.labels, nc).to(device) * nc  # attach class weights\n",
        "    model.names = names\n",
        "\n",
        "    # Start training\n",
        "    t0 = time.time()\n",
        "    nw = max(round(hyp['warmup_epochs'] * nb), 1000)  # number of warmup iterations, max(3 epochs, 1k iterations)\n",
        "    # nw = min(nw, (epochs - start_epoch) / 2 * nb)  # limit warmup to < 1/2 of training\n",
        "    maps = np.zeros(nc)  # mAP per class\n",
        "    results = (0, 0, 0, 0, 0, 0, 0)  # P, R, mAP@.5, mAP@.5-.95, val_loss(box, obj, cls)\n",
        "    scheduler.last_epoch = start_epoch - 1  # do not move\n",
        "    scaler = amp.GradScaler(enabled=cuda)\n",
        "    compute_loss_ota = ComputeLossOTA(model)  # init loss class\n",
        "    compute_loss = ComputeLoss(model)  # init loss class\n",
        "    logger.info(f'Image sizes {imgsz} train, {imgsz_test} test\\n'\n",
        "                f'Using {dataloader.num_workers} dataloader workers\\n'\n",
        "                f'Logging results to {save_dir}\\n'\n",
        "                f'Starting training for {epochs} epochs...')\n",
        "    torch.save(model, wdir / 'init.pt')\n",
        "    for epoch in range(start_epoch, epochs):  # epoch ------------------------------------------------------------------\n",
        "        model.train()\n",
        "\n",
        "        # Update image weights (optional)\n",
        "        if opt.image_weights:\n",
        "            # Generate indices\n",
        "            if rank in [-1, 0]:\n",
        "                cw = model.class_weights.cpu().numpy() * (1 - maps) ** 2 / nc  # class weights\n",
        "                iw = labels_to_image_weights(dataset.labels, nc=nc, class_weights=cw)  # image weights\n",
        "                dataset.indices = random.choices(range(dataset.n), weights=iw, k=dataset.n)  # rand weighted idx\n",
        "            # Broadcast if DDP\n",
        "            if rank != -1:\n",
        "                indices = (torch.tensor(dataset.indices) if rank == 0 else torch.zeros(dataset.n)).int()\n",
        "                dist.broadcast(indices, 0)\n",
        "                if rank != 0:\n",
        "                    dataset.indices = indices.cpu().numpy()\n",
        "\n",
        "        # Update mosaic border\n",
        "        # b = int(random.uniform(0.25 * imgsz, 0.75 * imgsz + gs) // gs * gs)\n",
        "        # dataset.mosaic_border = [b - imgsz, -b]  # height, width borders\n",
        "\n",
        "        mloss = torch.zeros(4, device=device)  # mean losses\n",
        "        if rank != -1:\n",
        "            dataloader.sampler.set_epoch(epoch)\n",
        "        pbar = enumerate(dataloader)\n",
        "        logger.info(('\\n' + '%10s' * 8) % ('Epoch', 'gpu_mem', 'box', 'obj', 'cls', 'total', 'labels', 'img_size'))\n",
        "        if rank in [-1, 0]:\n",
        "            pbar = tqdm(pbar, total=nb)  # progress bar\n",
        "        optimizer.zero_grad()\n",
        "        for i, (imgs, targets, paths, _) in pbar:  # batch -------------------------------------------------------------\n",
        "            ni = i + nb * epoch  # number integrated batches (since train start)\n",
        "            imgs = imgs.to(device, non_blocking=True).float() / 255.0  # uint8 to float32, 0-255 to 0.0-1.0\n",
        "\n",
        "            # Warmup\n",
        "            if ni <= nw:\n",
        "                xi = [0, nw]  # x interp\n",
        "                # model.gr = np.interp(ni, xi, [0.0, 1.0])  # iou loss ratio (obj_loss = 1.0 or iou)\n",
        "                accumulate = max(1, np.interp(ni, xi, [1, nbs / total_batch_size]).round())\n",
        "                for j, x in enumerate(optimizer.param_groups):\n",
        "                    # bias lr falls from 0.1 to lr0, all other lrs rise from 0.0 to lr0\n",
        "                    x['lr'] = np.interp(ni, xi, [hyp['warmup_bias_lr'] if j == 2 else 0.0, x['initial_lr'] * lf(epoch)])\n",
        "                    if 'momentum' in x:\n",
        "                        x['momentum'] = np.interp(ni, xi, [hyp['warmup_momentum'], hyp['momentum']])\n",
        "\n",
        "            # Multi-scale\n",
        "            if opt.multi_scale:\n",
        "                sz = random.randrange(imgsz * 0.5, imgsz * 1.5 + gs) // gs * gs  # size\n",
        "                sf = sz / max(imgs.shape[2:])  # scale factor\n",
        "                if sf != 1:\n",
        "                    ns = [math.ceil(x * sf / gs) * gs for x in imgs.shape[2:]]  # new shape (stretched to gs-multiple)\n",
        "                    imgs = F.interpolate(imgs, size=ns, mode='bilinear', align_corners=False)\n",
        "\n",
        "            # Forward\n",
        "            with amp.autocast(enabled=cuda):\n",
        "                pred = model(imgs)  # forward\n",
        "                if 'loss_ota' not in hyp or hyp['loss_ota'] == 1:\n",
        "                    loss, loss_items = compute_loss_ota(pred, targets.to(device), imgs)  # loss scaled by batch_size\n",
        "                else:\n",
        "                    loss, loss_items = compute_loss(pred, targets.to(device))  # loss scaled by batch_size\n",
        "                if rank != -1:\n",
        "                    loss *= opt.world_size  # gradient averaged between devices in DDP mode\n",
        "                if opt.quad:\n",
        "                    loss *= 4.\n",
        "\n",
        "            # Backward\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "            # Optimize\n",
        "            if ni % accumulate == 0:\n",
        "                scaler.step(optimizer)  # optimizer.step\n",
        "                scaler.update()\n",
        "                optimizer.zero_grad()\n",
        "                if ema:\n",
        "                    ema.update(model)\n",
        "\n",
        "            # Print\n",
        "            if rank in [-1, 0]:\n",
        "                mloss = (mloss * i + loss_items) / (i + 1)  # update mean losses\n",
        "                mem = '%.3gG' % (torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0)  # (GB)\n",
        "                s = ('%10s' * 2 + '%10.4g' * 6) % (\n",
        "                    '%g/%g' % (epoch, epochs - 1), mem, *mloss, targets.shape[0], imgs.shape[-1])\n",
        "                pbar.set_description(s)\n",
        "\n",
        "                # Plot\n",
        "                if plots and ni < 10:\n",
        "                    f = save_dir / f'train_batch{ni}.jpg'  # filename\n",
        "                    Thread(target=plot_images, args=(imgs, targets, paths, f), daemon=True).start()\n",
        "                    # if tb_writer:\n",
        "                    #     tb_writer.add_image(f, result, dataformats='HWC', global_step=epoch)\n",
        "                    #     tb_writer.add_graph(torch.jit.trace(model, imgs, strict=False), [])  # add model graph\n",
        "                elif plots and ni == 10 and wandb_logger.wandb:\n",
        "                    wandb_logger.log({\"Mosaics\": [wandb_logger.wandb.Image(str(x), caption=x.name) for x in\n",
        "                                                  save_dir.glob('train*.jpg') if x.exists()]})\n",
        "\n",
        "            # end batch ------------------------------------------------------------------------------------------------\n",
        "        # end epoch ----------------------------------------------------------------------------------------------------\n",
        "\n",
        "        # Scheduler\n",
        "        lr = [x['lr'] for x in optimizer.param_groups]  # for tensorboard\n",
        "        scheduler.step()\n",
        "\n",
        "        # DDP process 0 or single-GPU\n",
        "        if rank in [-1, 0]:\n",
        "            # mAP\n",
        "            ema.update_attr(model, include=['yaml', 'nc', 'hyp', 'gr', 'names', 'stride', 'class_weights'])\n",
        "            final_epoch = epoch + 1 == epochs\n",
        "            if not opt.notest or final_epoch:  # Calculate mAP\n",
        "                wandb_logger.current_epoch = epoch + 1\n",
        "                results, maps, times = test.test(data_dict,\n",
        "                                                 batch_size=batch_size * 2,\n",
        "                                                 imgsz=imgsz_test,\n",
        "                                                 model=ema.ema,\n",
        "                                                 single_cls=opt.single_cls,\n",
        "                                                 dataloader=testloader,\n",
        "                                                 save_dir=save_dir,\n",
        "                                                 verbose=nc < 50 and final_epoch,\n",
        "                                                 plots=plots and final_epoch,\n",
        "                                                 wandb_logger=wandb_logger,\n",
        "                                                 compute_loss=compute_loss,\n",
        "                                                 is_coco=is_coco,\n",
        "                                                 v5_metric=opt.v5_metric)\n",
        "\n",
        "            # Write\n",
        "            with open(results_file, 'a') as f:\n",
        "                f.write(s + '%10.4g' * 7 % results + '\\n')  # append metrics, val_loss\n",
        "            if len(opt.name) and opt.bucket:\n",
        "                os.system('gsutil cp %s gs://%s/results/results%s.txt' % (results_file, opt.bucket, opt.name))\n",
        "\n",
        "            # Log\n",
        "            tags = ['train/box_loss', 'train/obj_loss', 'train/cls_loss',  # train loss\n",
        "                    'metrics/precision', 'metrics/recall', 'metrics/mAP_0.5', 'metrics/mAP_0.5:0.95',\n",
        "                    'val/box_loss', 'val/obj_loss', 'val/cls_loss',  # val loss\n",
        "                    'x/lr0', 'x/lr1', 'x/lr2']  # params\n",
        "            for x, tag in zip(list(mloss[:-1]) + list(results) + lr, tags):\n",
        "                if tb_writer:\n",
        "                    tb_writer.add_scalar(tag, x, epoch)  # tensorboard\n",
        "                if wandb_logger.wandb:\n",
        "                    wandb_logger.log({tag: x})  # W&B\n",
        "\n",
        "            # Update best mAP\n",
        "            fi = fitness(np.array(results).reshape(1, -1))  # weighted combination of [P, R, mAP@.5, mAP@.5-.95]\n",
        "            if fi > best_fitness:\n",
        "                best_fitness = fi\n",
        "            wandb_logger.end_epoch(best_result=best_fitness == fi)\n",
        "\n",
        "            # Save model\n",
        "            if (not opt.nosave) or (final_epoch and not opt.evolve):  # if save\n",
        "                ckpt = {'epoch': epoch,\n",
        "                        'best_fitness': best_fitness,\n",
        "                        'training_results': results_file.read_text(),\n",
        "                        'model': deepcopy(model.module if is_parallel(model) else model).half(),\n",
        "                        'ema': deepcopy(ema.ema).half(),\n",
        "                        'updates': ema.updates,\n",
        "                        'optimizer': optimizer.state_dict(),\n",
        "                        'wandb_id': wandb_logger.wandb_run.id if wandb_logger.wandb else None}\n",
        "\n",
        "                # Save last, best and delete\n",
        "                torch.save(ckpt, last)\n",
        "                if best_fitness == fi:\n",
        "                    torch.save(ckpt, best)\n",
        "                if (best_fitness == fi) and (epoch >= 200):\n",
        "                    torch.save(ckpt, wdir / 'best_{:03d}.pt'.format(epoch))\n",
        "                if epoch == 0:\n",
        "                    torch.save(ckpt, wdir / 'epoch_{:03d}.pt'.format(epoch))\n",
        "                elif ((epoch+1) % 25) == 0:\n",
        "                    torch.save(ckpt, wdir / 'epoch_{:03d}.pt'.format(epoch))\n",
        "                elif epoch >= (epochs-5):\n",
        "                    torch.save(ckpt, wdir / 'epoch_{:03d}.pt'.format(epoch))\n",
        "                if wandb_logger.wandb:\n",
        "                    if ((epoch + 1) % opt.save_period == 0 and not final_epoch) and opt.save_period != -1:\n",
        "                        wandb_logger.log_model(\n",
        "                            last.parent, opt, epoch, fi, best_model=best_fitness == fi)\n",
        "                del ckpt\n",
        "\n",
        "        # end epoch ----------------------------------------------------------------------------------------------------\n",
        "    # end training\n",
        "    if rank in [-1, 0]:\n",
        "        # Plots\n",
        "        if plots:\n",
        "            plot_results(save_dir=save_dir)  # save as results.png\n",
        "            if wandb_logger.wandb:\n",
        "                files = ['results.png', 'confusion_matrix.png', *[f'{x}_curve.png' for x in ('F1', 'PR', 'P', 'R')]]\n",
        "                wandb_logger.log({\"Results\": [wandb_logger.wandb.Image(str(save_dir / f), caption=f) for f in files\n",
        "                                              if (save_dir / f).exists()]})\n",
        "        # Test best.pt\n",
        "        logger.info('%g epochs completed in %.3f hours.\\n' % (epoch - start_epoch + 1, (time.time() - t0) / 3600))\n",
        "        if opt.data.endswith('coco.yaml') and nc == 80:  # if COCO\n",
        "            for m in (last, best) if best.exists() else (last):  # speed, mAP tests\n",
        "                results, _, _ = test.test(opt.data,\n",
        "                                          batch_size=batch_size * 2,\n",
        "                                          imgsz=imgsz_test,\n",
        "                                          conf_thres=0.001,\n",
        "                                          iou_thres=0.7,\n",
        "                                          model=attempt_load(m, device).half(),\n",
        "                                          single_cls=opt.single_cls,\n",
        "                                          dataloader=testloader,\n",
        "                                          save_dir=save_dir,\n",
        "                                          save_json=True,\n",
        "                                          plots=False,\n",
        "                                          is_coco=is_coco,\n",
        "                                          v5_metric=opt.v5_metric)\n",
        "\n",
        "        # Strip optimizers\n",
        "        final = best if best.exists() else last  # final model\n",
        "        for f in last, best:\n",
        "            if f.exists():\n",
        "                strip_optimizer(f)  # strip optimizers\n",
        "        if opt.bucket:\n",
        "            os.system(f'gsutil cp {final} gs://{opt.bucket}/weights')  # upload\n",
        "        if wandb_logger.wandb and not opt.evolve:  # Log the stripped model\n",
        "            wandb_logger.wandb.log_artifact(str(final), type='model',\n",
        "                                            name='run_' + wandb_logger.wandb_run.id + '_model',\n",
        "                                            aliases=['last', 'best', 'stripped'])\n",
        "        wandb_logger.finish_run()\n",
        "    else:\n",
        "        dist.destroy_process_group()\n",
        "    torch.cuda.empty_cache()\n",
        "    return results\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--weights', type=str, default='yolo7.pt', help='initial weights path')\n",
        "    parser.add_argument('--cfg', type=str, default='', help='model.yaml path')\n",
        "    parser.add_argument('--data', type=str, default='data/coco.yaml', help='data.yaml path')\n",
        "    parser.add_argument('--hyp', type=str, default='data/hyp.scratch.p5.yaml', help='hyperparameters path')\n",
        "    parser.add_argument('--epochs', type=int, default=300)\n",
        "    parser.add_argument('--batch-size', type=int, default=16, help='total batch size for all GPUs')\n",
        "    parser.add_argument('--img-size', nargs='+', type=int, default=[640, 640], help='[train, test] image sizes')\n",
        "    parser.add_argument('--rect', action='store_true', help='rectangular training')\n",
        "    parser.add_argument('--resume', nargs='?', const=True, default=False, help='resume most recent training')\n",
        "    parser.add_argument('--nosave', action='store_true', help='only save final checkpoint')\n",
        "    parser.add_argument('--notest', action='store_true', help='only test final epoch')\n",
        "    parser.add_argument('--noautoanchor', action='store_true', help='disable autoanchor check')\n",
        "    parser.add_argument('--evolve', action='store_true', help='evolve hyperparameters')\n",
        "    parser.add_argument('--bucket', type=str, default='', help='gsutil bucket')\n",
        "    parser.add_argument('--cache-images', action='store_true', help='cache images for faster training')\n",
        "    parser.add_argument('--image-weights', action='store_true', help='use weighted image selection for training')\n",
        "    parser.add_argument('--device', default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')\n",
        "    parser.add_argument('--multi-scale', action='store_true', help='vary img-size +/- 50%%')\n",
        "    parser.add_argument('--single-cls', action='store_true', help='train multi-class data as single-class')\n",
        "    parser.add_argument('--adam', action='store_true', help='use torch.optim.Adam() optimizer')\n",
        "    parser.add_argument('--sync-bn', action='store_true', help='use SyncBatchNorm, only available in DDP mode')\n",
        "    parser.add_argument('--local_rank', type=int, default=-1, help='DDP parameter, do not modify')\n",
        "    parser.add_argument('--workers', type=int, default=8, help='maximum number of dataloader workers')\n",
        "    parser.add_argument('--project', default='runs/train', help='save to project/name')\n",
        "    parser.add_argument('--entity', default=None, help='W&B entity')\n",
        "    parser.add_argument('--name', default='exp', help='save to project/name')\n",
        "    parser.add_argument('--exist-ok', action='store_true', help='existing project/name ok, do not increment')\n",
        "    parser.add_argument('--quad', action='store_true', help='quad dataloader')\n",
        "    parser.add_argument('--linear-lr', action='store_true', help='linear LR')\n",
        "    parser.add_argument('--label-smoothing', type=float, default=0.0, help='Label smoothing epsilon')\n",
        "    parser.add_argument('--upload_dataset', action='store_true', help='Upload dataset as W&B artifact table')\n",
        "    parser.add_argument('--bbox_interval', type=int, default=-1, help='Set bounding-box image logging interval for W&B')\n",
        "    parser.add_argument('--save_period', type=int, default=-1, help='Log model after every \"save_period\" epoch')\n",
        "    parser.add_argument('--artifact_alias', type=str, default=\"latest\", help='version of dataset artifact to be used')\n",
        "    parser.add_argument('--freeze', nargs='+', type=int, default=[0], help='Freeze layers: backbone of yolov7=50, first3=0 1 2')\n",
        "    parser.add_argument('--v5-metric', action='store_true', help='assume maximum recall as 1.0 in AP calculation')\n",
        "    opt = parser.parse_args()\n",
        "\n",
        "    # Set DDP variables\n",
        "    opt.world_size = int(os.environ['WORLD_SIZE']) if 'WORLD_SIZE' in os.environ else 1\n",
        "    opt.global_rank = int(os.environ['RANK']) if 'RANK' in os.environ else -1\n",
        "    set_logging(opt.global_rank)\n",
        "    #if opt.global_rank in [-1, 0]:\n",
        "    #    check_git_status()\n",
        "    #    check_requirements()\n",
        "\n",
        "    # Resume\n",
        "    wandb_run = check_wandb_resume(opt)\n",
        "    if opt.resume and not wandb_run:  # resume an interrupted run\n",
        "        ckpt = opt.resume if isinstance(opt.resume, str) else get_latest_run()  # specified or most recent path\n",
        "        assert os.path.isfile(ckpt), 'ERROR: --resume checkpoint does not exist'\n",
        "        apriori = opt.global_rank, opt.local_rank\n",
        "        with open(Path(ckpt).parent.parent / 'opt.yaml') as f:\n",
        "            opt = argparse.Namespace(**yaml.load(f, Loader=yaml.SafeLoader))  # replace\n",
        "        opt.cfg, opt.weights, opt.resume, opt.batch_size, opt.global_rank, opt.local_rank = '', ckpt, True, opt.total_batch_size, *apriori  # reinstate\n",
        "        logger.info('Resuming training from %s' % ckpt)\n",
        "    else:\n",
        "        # opt.hyp = opt.hyp or ('hyp.finetune.yaml' if opt.weights else 'hyp.scratch.yaml')\n",
        "        opt.data, opt.cfg, opt.hyp = check_file(opt.data), check_file(opt.cfg), check_file(opt.hyp)  # check files\n",
        "        assert len(opt.cfg) or len(opt.weights), 'either --cfg or --weights must be specified'\n",
        "        opt.img_size.extend([opt.img_size[-1]] * (2 - len(opt.img_size)))  # extend to 2 sizes (train, test)\n",
        "        opt.name = 'evolve' if opt.evolve else opt.name\n",
        "        opt.save_dir = increment_path(Path(opt.project) / opt.name, exist_ok=opt.exist_ok | opt.evolve)  # increment run\n",
        "\n",
        "    # DDP mode\n",
        "    opt.total_batch_size = opt.batch_size\n",
        "    device = select_device(opt.device, batch_size=opt.batch_size)\n",
        "    if opt.local_rank != -1:\n",
        "        assert torch.cuda.device_count() > opt.local_rank\n",
        "        torch.cuda.set_device(opt.local_rank)\n",
        "        device = torch.device('cuda', opt.local_rank)\n",
        "        dist.init_process_group(backend='nccl', init_method='env://')  # distributed backend\n",
        "        assert opt.batch_size % opt.world_size == 0, '--batch-size must be multiple of CUDA device count'\n",
        "        opt.batch_size = opt.total_batch_size // opt.world_size\n",
        "\n",
        "    # Hyperparameters\n",
        "    with open(opt.hyp) as f:\n",
        "        hyp = yaml.load(f, Loader=yaml.SafeLoader)  # load hyps\n",
        "\n",
        "    # Train\n",
        "    logger.info(opt)\n",
        "    if not opt.evolve:\n",
        "        tb_writer = None  # init loggers\n",
        "        if opt.global_rank in [-1, 0]:\n",
        "            prefix = colorstr('tensorboard: ')\n",
        "            logger.info(f\"{prefix}Start with 'tensorboard --logdir {opt.project}', view at http://localhost:6006/\")\n",
        "            tb_writer = SummaryWriter(opt.save_dir)  # Tensorboard\n",
        "        train(hyp, opt, device, tb_writer)\n",
        "\n",
        "    # Evolve hyperparameters (optional)\n",
        "    else:\n",
        "        # Hyperparameter evolution metadata (mutation scale 0-1, lower_limit, upper_limit)\n",
        "        meta = {'lr0': (1, 1e-5, 1e-1),  # initial learning rate (SGD=1E-2, Adam=1E-3)\n",
        "                'lrf': (1, 0.01, 1.0),  # final OneCycleLR learning rate (lr0 * lrf)\n",
        "                'momentum': (0.3, 0.6, 0.98),  # SGD momentum/Adam beta1\n",
        "                'weight_decay': (1, 0.0, 0.001),  # optimizer weight decay\n",
        "                'warmup_epochs': (1, 0.0, 5.0),  # warmup epochs (fractions ok)\n",
        "                'warmup_momentum': (1, 0.0, 0.95),  # warmup initial momentum\n",
        "                'warmup_bias_lr': (1, 0.0, 0.2),  # warmup initial bias lr\n",
        "                'box': (1, 0.02, 0.2),  # box loss gain\n",
        "                'cls': (1, 0.2, 4.0),  # cls loss gain\n",
        "                'cls_pw': (1, 0.5, 2.0),  # cls BCELoss positive_weight\n",
        "                'obj': (1, 0.2, 4.0),  # obj loss gain (scale with pixels)\n",
        "                'obj_pw': (1, 0.5, 2.0),  # obj BCELoss positive_weight\n",
        "                'iou_t': (0, 0.1, 0.7),  # IoU training threshold\n",
        "                'anchor_t': (1, 2.0, 8.0),  # anchor-multiple threshold\n",
        "                'anchors': (2, 2.0, 10.0),  # anchors per output grid (0 to ignore)\n",
        "                'fl_gamma': (0, 0.0, 2.0),  # focal loss gamma (efficientDet default gamma=1.5)\n",
        "                'hsv_h': (1, 0.0, 0.1),  # image HSV-Hue augmentation (fraction)\n",
        "                'hsv_s': (1, 0.0, 0.9),  # image HSV-Saturation augmentation (fraction)\n",
        "                'hsv_v': (1, 0.0, 0.9),  # image HSV-Value augmentation (fraction)\n",
        "                'degrees': (1, 0.0, 45.0),  # image rotation (+/- deg)\n",
        "                'translate': (1, 0.0, 0.9),  # image translation (+/- fraction)\n",
        "                'scale': (1, 0.0, 0.9),  # image scale (+/- gain)\n",
        "                'shear': (1, 0.0, 10.0),  # image shear (+/- deg)\n",
        "                'perspective': (0, 0.0, 0.001),  # image perspective (+/- fraction), range 0-0.001\n",
        "                'flipud': (1, 0.0, 1.0),  # image flip up-down (probability)\n",
        "                'fliplr': (0, 0.0, 1.0),  # image flip left-right (probability)\n",
        "                'mosaic': (1, 0.0, 1.0),  # image mixup (probability)\n",
        "                'mixup': (1, 0.0, 1.0),   # image mixup (probability)\n",
        "                'copy_paste': (1, 0.0, 1.0),  # segment copy-paste (probability)\n",
        "                'paste_in': (1, 0.0, 1.0)}    # segment copy-paste (probability)\n",
        "\n",
        "        with open(opt.hyp, errors='ignore') as f:\n",
        "            hyp = yaml.safe_load(f)  # load hyps dict\n",
        "            if 'anchors' not in hyp:  # anchors commented in hyp.yaml\n",
        "                hyp['anchors'] = 3\n",
        "\n",
        "        assert opt.local_rank == -1, 'DDP mode not implemented for --evolve'\n",
        "        opt.notest, opt.nosave = True, True  # only test/save final epoch\n",
        "        # ei = [isinstance(x, (int, float)) for x in hyp.values()]  # evolvable indices\n",
        "        yaml_file = Path(opt.save_dir) / 'hyp_evolved.yaml'  # save best result here\n",
        "        if opt.bucket:\n",
        "            os.system('gsutil cp gs://%s/evolve.txt .' % opt.bucket)  # download evolve.txt if exists\n",
        "\n",
        "        for _ in range(300):  # generations to evolve\n",
        "            if Path('evolve.txt').exists():  # if evolve.txt exists: select best hyps and mutate\n",
        "                # Select parent(s)\n",
        "                parent = 'single'  # parent selection method: 'single' or 'weighted'\n",
        "                x = np.loadtxt('evolve.txt', ndmin=2)\n",
        "                n = min(5, len(x))  # number of previous results to consider\n",
        "                x = x[np.argsort(-fitness(x))][:n]  # top n mutations\n",
        "                w = fitness(x) - fitness(x).min()  # weights\n",
        "                if parent == 'single' or len(x) == 1:\n",
        "                    # x = x[random.randint(0, n - 1)]  # random selection\n",
        "                    x = x[random.choices(range(n), weights=w)[0]]  # weighted selection\n",
        "                elif parent == 'weighted':\n",
        "                    x = (x * w.reshape(n, 1)).sum(0) / w.sum()  # weighted combination\n",
        "\n",
        "                # Mutate\n",
        "                mp, s = 0.8, 0.2  # mutation probability, sigma\n",
        "                npr = np.random\n",
        "                npr.seed(int(time.time()))\n",
        "                g = np.array([x[0] for x in meta.values()])  # gains 0-1\n",
        "                ng = len(meta)\n",
        "                v = np.ones(ng)\n",
        "                while all(v == 1):  # mutate until a change occurs (prevent duplicates)\n",
        "                    v = (g * (npr.random(ng) < mp) * npr.randn(ng) * npr.random() * s + 1).clip(0.3, 3.0)\n",
        "                for i, k in enumerate(hyp.keys()):  # plt.hist(v.ravel(), 300)\n",
        "                    hyp[k] = float(x[i + 7] * v[i])  # mutate\n",
        "\n",
        "            # Constrain to limits\n",
        "            for k, v in meta.items():\n",
        "                hyp[k] = max(hyp[k], v[1])  # lower limit\n",
        "                hyp[k] = min(hyp[k], v[2])  # upper limit\n",
        "                hyp[k] = round(hyp[k], 5)  # significant digits\n",
        "\n",
        "            # Train mutation\n",
        "            results = train(hyp.copy(), opt, device)\n",
        "\n",
        "            # Write mutation results\n",
        "            print_mutation(hyp.copy(), results, yaml_file, opt.bucket)\n",
        "\n",
        "        # Plot results\n",
        "        plot_evolution(yaml_file)\n",
        "        print(f'Hyperparameter evolution complete. Best results saved as: {yaml_file}\\n'\n",
        "              f'Command to train a new model with these hyperparameters: $ python train.py --hyp {yaml_file}')\n"
      ],
      "metadata": {
        "id": "3mQQCEa46Es-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing"
      ],
      "metadata": {
        "id": "ub2qi7-y6OZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "from threading import Thread\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import yaml\n",
        "from tqdm import tqdm\n",
        "\n",
        "from models.experimental import attempt_load\n",
        "from utils.datasets import create_dataloader\n",
        "from utils.general import coco80_to_coco91_class, check_dataset, check_file, check_img_size, check_requirements, \\\n",
        "    box_iou, non_max_suppression, scale_coords, xyxy2xywh, xywh2xyxy, set_logging, increment_path, colorstr\n",
        "from utils.metrics import ap_per_class, ConfusionMatrix\n",
        "from utils.plots import plot_images, output_to_target, plot_study_txt\n",
        "from utils.torch_utils import select_device, time_synchronized, TracedModel\n",
        "\n",
        "\n",
        "def test(data,\n",
        "         weights=None,\n",
        "         batch_size=32,\n",
        "         imgsz=640,\n",
        "         conf_thres=0.001,\n",
        "         iou_thres=0.6,  # for NMS\n",
        "         save_json=False,\n",
        "         single_cls=False,\n",
        "         augment=False,\n",
        "         verbose=False,\n",
        "         model=None,\n",
        "         dataloader=None,\n",
        "         save_dir=Path(''),  # for saving images\n",
        "         save_txt=False,  # for auto-labelling\n",
        "         save_hybrid=False,  # for hybrid auto-labelling\n",
        "         save_conf=False,  # save auto-label confidences\n",
        "         plots=True,\n",
        "         wandb_logger=None,\n",
        "         compute_loss=None,\n",
        "         half_precision=True,\n",
        "         trace=False,\n",
        "         is_coco=False,\n",
        "         v5_metric=False):\n",
        "    # Initialize/load model and set device\n",
        "    training = model is not None\n",
        "    if training:  # called by train.py\n",
        "        device = next(model.parameters()).device  # get model device\n",
        "\n",
        "    else:  # called directly\n",
        "        set_logging()\n",
        "        device = select_device(opt.device, batch_size=batch_size)\n",
        "\n",
        "        # Directories\n",
        "        save_dir = Path(increment_path(Path(opt.project) / opt.name, exist_ok=opt.exist_ok))  # increment run\n",
        "        (save_dir / 'labels' if save_txt else save_dir).mkdir(parents=True, exist_ok=True)  # make dir\n",
        "\n",
        "        # Load model\n",
        "        model = attempt_load(weights, map_location=device)  # load FP32 model\n",
        "        gs = max(int(model.stride.max()), 32)  # grid size (max stride)\n",
        "        imgsz = check_img_size(imgsz, s=gs)  # check img_size\n",
        "\n",
        "        if trace:\n",
        "            model = TracedModel(model, device, imgsz)\n",
        "\n",
        "    # Half\n",
        "    half = device.type != 'cpu' and half_precision  # half precision only supported on CUDA\n",
        "    if half:\n",
        "        model.half()\n",
        "\n",
        "    # Configure\n",
        "    model.eval()\n",
        "    if isinstance(data, str):\n",
        "        is_coco = data.endswith('coco.yaml')\n",
        "        with open(data) as f:\n",
        "            data = yaml.load(f, Loader=yaml.SafeLoader)\n",
        "    check_dataset(data)  # check\n",
        "    nc = 1 if single_cls else int(data['nc'])  # number of classes\n",
        "    iouv = torch.linspace(0.5, 0.95, 10).to(device)  # iou vector for mAP@0.5:0.95\n",
        "    niou = iouv.numel()\n",
        "\n",
        "    # Logging\n",
        "    log_imgs = 0\n",
        "    if wandb_logger and wandb_logger.wandb:\n",
        "        log_imgs = min(wandb_logger.log_imgs, 100)\n",
        "    # Dataloader\n",
        "    if not training:\n",
        "        if device.type != 'cpu':\n",
        "            model(torch.zeros(1, 3, imgsz, imgsz).to(device).type_as(next(model.parameters())))  # run once\n",
        "        task = opt.task if opt.task in ('train', 'val', 'test') else 'val'  # path to train/val/test images\n",
        "        dataloader = create_dataloader(data[task], imgsz, batch_size, gs, opt, pad=0.5, rect=True,\n",
        "                                       prefix=colorstr(f'{task}: '))[0]\n",
        "\n",
        "    if v5_metric:\n",
        "        print(\"Testing with YOLOv5 AP metric...\")\n",
        "\n",
        "    seen = 0\n",
        "    confusion_matrix = ConfusionMatrix(nc=nc)\n",
        "    names = {k: v for k, v in enumerate(model.names if hasattr(model, 'names') else model.module.names)}\n",
        "    coco91class = coco80_to_coco91_class()\n",
        "    s = ('%20s' + '%12s' * 6) % ('Class', 'Images', 'Labels', 'P', 'R', 'mAP@.5', 'mAP@.5:.95')\n",
        "    p, r, f1, mp, mr, map50, map, t0, t1 = 0., 0., 0., 0., 0., 0., 0., 0., 0.\n",
        "    loss = torch.zeros(3, device=device)\n",
        "    jdict, stats, ap, ap_class, wandb_images = [], [], [], [], []\n",
        "    for batch_i, (img, targets, paths, shapes) in enumerate(tqdm(dataloader, desc=s)):\n",
        "        img = img.to(device, non_blocking=True)\n",
        "        img = img.half() if half else img.float()  # uint8 to fp16/32\n",
        "        img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
        "        targets = targets.to(device)\n",
        "        nb, _, height, width = img.shape  # batch size, channels, height, width\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # Run model\n",
        "            t = time_synchronized()\n",
        "            out, train_out = model(img, augment=augment)  # inference and training outputs\n",
        "            t0 += time_synchronized() - t\n",
        "\n",
        "            # Compute loss\n",
        "            if compute_loss:\n",
        "                loss += compute_loss([x.float() for x in train_out], targets)[1][:3]  # box, obj, cls\n",
        "\n",
        "            # Run NMS\n",
        "            targets[:, 2:] *= torch.Tensor([width, height, width, height]).to(device)  # to pixels\n",
        "            lb = [targets[targets[:, 0] == i, 1:] for i in range(nb)] if save_hybrid else []  # for autolabelling\n",
        "            t = time_synchronized()\n",
        "            out = non_max_suppression(out, conf_thres=conf_thres, iou_thres=iou_thres, labels=lb, multi_label=True)\n",
        "            t1 += time_synchronized() - t\n",
        "\n",
        "        # Statistics per image\n",
        "        for si, pred in enumerate(out):\n",
        "            labels = targets[targets[:, 0] == si, 1:]\n",
        "            nl = len(labels)\n",
        "            tcls = labels[:, 0].tolist() if nl else []  # target class\n",
        "            path = Path(paths[si])\n",
        "            seen += 1\n",
        "\n",
        "            if len(pred) == 0:\n",
        "                if nl:\n",
        "                    stats.append((torch.zeros(0, niou, dtype=torch.bool), torch.Tensor(), torch.Tensor(), tcls))\n",
        "                continue\n",
        "\n",
        "            # Predictions\n",
        "            predn = pred.clone()\n",
        "            scale_coords(img[si].shape[1:], predn[:, :4], shapes[si][0], shapes[si][1])  # native-space pred\n",
        "\n",
        "            # Append to text file\n",
        "            if save_txt:\n",
        "                gn = torch.tensor(shapes[si][0])[[1, 0, 1, 0]]  # normalization gain whwh\n",
        "                for *xyxy, conf, cls in predn.tolist():\n",
        "                    xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh\n",
        "                    line = (cls, *xywh, conf) if save_conf else (cls, *xywh)  # label format\n",
        "                    with open(save_dir / 'labels' / (path.stem + '.txt'), 'a') as f:\n",
        "                        f.write(('%g ' * len(line)).rstrip() % line + '\\n')\n",
        "\n",
        "            # W&B logging - Media Panel Plots\n",
        "            if len(wandb_images) < log_imgs and wandb_logger.current_epoch > 0:  # Check for test operation\n",
        "                if wandb_logger.current_epoch % wandb_logger.bbox_interval == 0:\n",
        "                    box_data = [{\"position\": {\"minX\": xyxy[0], \"minY\": xyxy[1], \"maxX\": xyxy[2], \"maxY\": xyxy[3]},\n",
        "                                 \"class_id\": int(cls),\n",
        "                                 \"box_caption\": \"%s %.3f\" % (names[cls], conf),\n",
        "                                 \"scores\": {\"class_score\": conf},\n",
        "                                 \"domain\": \"pixel\"} for *xyxy, conf, cls in pred.tolist()]\n",
        "                    boxes = {\"predictions\": {\"box_data\": box_data, \"class_labels\": names}}  # inference-space\n",
        "                    wandb_images.append(wandb_logger.wandb.Image(img[si], boxes=boxes, caption=path.name))\n",
        "            wandb_logger.log_training_progress(predn, path, names) if wandb_logger and wandb_logger.wandb_run else None\n",
        "\n",
        "            # Append to pycocotools JSON dictionary\n",
        "            if save_json:\n",
        "                # [{\"image_id\": 42, \"category_id\": 18, \"bbox\": [258.15, 41.29, 348.26, 243.78], \"score\": 0.236}, ...\n",
        "                image_id = int(path.stem) if path.stem.isnumeric() else path.stem\n",
        "                box = xyxy2xywh(predn[:, :4])  # xywh\n",
        "                box[:, :2] -= box[:, 2:] / 2  # xy center to top-left corner\n",
        "                for p, b in zip(pred.tolist(), box.tolist()):\n",
        "                    jdict.append({'image_id': image_id,\n",
        "                                  'category_id': coco91class[int(p[5])] if is_coco else int(p[5]),\n",
        "                                  'bbox': [round(x, 3) for x in b],\n",
        "                                  'score': round(p[4], 5)})\n",
        "\n",
        "            # Assign all predictions as incorrect\n",
        "            correct = torch.zeros(pred.shape[0], niou, dtype=torch.bool, device=device)\n",
        "            if nl:\n",
        "                detected = []  # target indices\n",
        "                tcls_tensor = labels[:, 0]\n",
        "\n",
        "                # target boxes\n",
        "                tbox = xywh2xyxy(labels[:, 1:5])\n",
        "                scale_coords(img[si].shape[1:], tbox, shapes[si][0], shapes[si][1])  # native-space labels\n",
        "                if plots:\n",
        "                    confusion_matrix.process_batch(predn, torch.cat((labels[:, 0:1], tbox), 1))\n",
        "\n",
        "                # Per target class\n",
        "                for cls in torch.unique(tcls_tensor):\n",
        "                    ti = (cls == tcls_tensor).nonzero(as_tuple=False).view(-1)  # prediction indices\n",
        "                    pi = (cls == pred[:, 5]).nonzero(as_tuple=False).view(-1)  # target indices\n",
        "\n",
        "                    # Search for detections\n",
        "                    if pi.shape[0]:\n",
        "                        # Prediction to target ious\n",
        "                        ious, i = box_iou(predn[pi, :4], tbox[ti]).max(1)  # best ious, indices\n",
        "\n",
        "                        # Append detections\n",
        "                        detected_set = set()\n",
        "                        for j in (ious > iouv[0]).nonzero(as_tuple=False):\n",
        "                            d = ti[i[j]]  # detected target\n",
        "                            if d.item() not in detected_set:\n",
        "                                detected_set.add(d.item())\n",
        "                                detected.append(d)\n",
        "                                correct[pi[j]] = ious[j] > iouv  # iou_thres is 1xn\n",
        "                                if len(detected) == nl:  # all targets already located in image\n",
        "                                    break\n",
        "\n",
        "            # Append statistics (correct, conf, pcls, tcls)\n",
        "            stats.append((correct.cpu(), pred[:, 4].cpu(), pred[:, 5].cpu(), tcls))\n",
        "\n",
        "        # Plot images\n",
        "        if plots and batch_i < 3:\n",
        "            f = save_dir / f'test_batch{batch_i}_labels.jpg'  # labels\n",
        "            Thread(target=plot_images, args=(img, targets, paths, f, names), daemon=True).start()\n",
        "            f = save_dir / f'test_batch{batch_i}_pred.jpg'  # predictions\n",
        "            Thread(target=plot_images, args=(img, output_to_target(out), paths, f, names), daemon=True).start()\n",
        "\n",
        "    # Compute statistics\n",
        "    stats = [np.concatenate(x, 0) for x in zip(*stats)]  # to numpy\n",
        "    if len(stats) and stats[0].any():\n",
        "        p, r, ap, f1, ap_class = ap_per_class(*stats, plot=plots, v5_metric=v5_metric, save_dir=save_dir, names=names)\n",
        "        ap50, ap = ap[:, 0], ap.mean(1)  # AP@0.5, AP@0.5:0.95\n",
        "        mp, mr, map50, map = p.mean(), r.mean(), ap50.mean(), ap.mean()\n",
        "        nt = np.bincount(stats[3].astype(np.int64), minlength=nc)  # number of targets per class\n",
        "    else:\n",
        "        nt = torch.zeros(1)\n",
        "\n",
        "    # Print results\n",
        "    pf = '%20s' + '%12i' * 2 + '%12.3g' * 4  # print format\n",
        "    print(pf % ('all', seen, nt.sum(), mp, mr, map50, map))\n",
        "\n",
        "    # Print results per class\n",
        "    if (verbose or (nc < 50 and not training)) and nc > 1 and len(stats):\n",
        "        for i, c in enumerate(ap_class):\n",
        "            print(pf % (names[c], seen, nt[c], p[i], r[i], ap50[i], ap[i]))\n",
        "\n",
        "    # Print speeds\n",
        "    t = tuple(x / seen * 1E3 for x in (t0, t1, t0 + t1)) + (imgsz, imgsz, batch_size)  # tuple\n",
        "    if not training:\n",
        "        print('Speed: %.1f/%.1f/%.1f ms inference/NMS/total per %gx%g image at batch-size %g' % t)\n",
        "\n",
        "    # Plots\n",
        "    if plots:\n",
        "        confusion_matrix.plot(save_dir=save_dir, names=list(names.values()))\n",
        "        if wandb_logger and wandb_logger.wandb:\n",
        "            val_batches = [wandb_logger.wandb.Image(str(f), caption=f.name) for f in sorted(save_dir.glob('test*.jpg'))]\n",
        "            wandb_logger.log({\"Validation\": val_batches})\n",
        "    if wandb_images:\n",
        "        wandb_logger.log({\"Bounding Box Debugger/Images\": wandb_images})\n",
        "\n",
        "    # Save JSON\n",
        "    if save_json and len(jdict):\n",
        "        w = Path(weights[0] if isinstance(weights, list) else weights).stem if weights is not None else ''  # weights\n",
        "        anno_json = './coco/annotations/instances_val2017.json'  # annotations json\n",
        "        pred_json = str(save_dir / f\"{w}_predictions.json\")  # predictions json\n",
        "        print('\\nEvaluating pycocotools mAP... saving %s...' % pred_json)\n",
        "        with open(pred_json, 'w') as f:\n",
        "            json.dump(jdict, f)\n",
        "\n",
        "        try:  # https://github.com/cocodataset/cocoapi/blob/master/PythonAPI/pycocoEvalDemo.ipynb\n",
        "            from pycocotools.coco import COCO\n",
        "            from pycocotools.cocoeval import COCOeval\n",
        "\n",
        "            anno = COCO(anno_json)  # init annotations api\n",
        "            pred = anno.loadRes(pred_json)  # init predictions api\n",
        "            eval = COCOeval(anno, pred, 'bbox')\n",
        "            if is_coco:\n",
        "                eval.params.imgIds = [int(Path(x).stem) for x in dataloader.dataset.img_files]  # image IDs to evaluate\n",
        "            eval.evaluate()\n",
        "            eval.accumulate()\n",
        "            eval.summarize()\n",
        "            map, map50 = eval.stats[:2]  # update results (mAP@0.5:0.95, mAP@0.5)\n",
        "        except Exception as e:\n",
        "            print(f'pycocotools unable to run: {e}')\n",
        "\n",
        "    # Return results\n",
        "    model.float()  # for training\n",
        "    if not training:\n",
        "        s = f\"\\n{len(list(save_dir.glob('labels/*.txt')))} labels saved to {save_dir / 'labels'}\" if save_txt else ''\n",
        "        print(f\"Results saved to {save_dir}{s}\")\n",
        "    maps = np.zeros(nc) + map\n",
        "    for i, c in enumerate(ap_class):\n",
        "        maps[c] = ap[i]\n",
        "    return (mp, mr, map50, map, *(loss.cpu() / len(dataloader)).tolist()), maps, t\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser(prog='test.py')\n",
        "    parser.add_argument('--weights', nargs='+', type=str, default='yolov7.pt', help='model.pt path(s)')\n",
        "    parser.add_argument('--data', type=str, default='data/coco.yaml', help='*.data path')\n",
        "    parser.add_argument('--batch-size', type=int, default=32, help='size of each image batch')\n",
        "    parser.add_argument('--img-size', type=int, default=640, help='inference size (pixels)')\n",
        "    parser.add_argument('--conf-thres', type=float, default=0.001, help='object confidence threshold')\n",
        "    parser.add_argument('--iou-thres', type=float, default=0.65, help='IOU threshold for NMS')\n",
        "    parser.add_argument('--task', default='val', help='train, val, test, speed or study')\n",
        "    parser.add_argument('--device', default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')\n",
        "    parser.add_argument('--single-cls', action='store_true', help='treat as single-class dataset')\n",
        "    parser.add_argument('--augment', action='store_true', help='augmented inference')\n",
        "    parser.add_argument('--verbose', action='store_true', help='report mAP by class')\n",
        "    parser.add_argument('--save-txt', action='store_true', help='save results to *.txt')\n",
        "    parser.add_argument('--save-hybrid', action='store_true', help='save label+prediction hybrid results to *.txt')\n",
        "    parser.add_argument('--save-conf', action='store_true', help='save confidences in --save-txt labels')\n",
        "    parser.add_argument('--save-json', action='store_true', help='save a cocoapi-compatible JSON results file')\n",
        "    parser.add_argument('--project', default='runs/test', help='save to project/name')\n",
        "    parser.add_argument('--name', default='exp', help='save to project/name')\n",
        "    parser.add_argument('--exist-ok', action='store_true', help='existing project/name ok, do not increment')\n",
        "    parser.add_argument('--no-trace', action='store_true', help='don`t trace model')\n",
        "    parser.add_argument('--v5-metric', action='store_true', help='assume maximum recall as 1.0 in AP calculation')\n",
        "    opt = parser.parse_args()\n",
        "    opt.save_json |= opt.data.endswith('coco.yaml')\n",
        "    opt.data = check_file(opt.data)  # check file\n",
        "    print(opt)\n",
        "    #check_requirements()\n",
        "\n",
        "    if opt.task in ('train', 'val', 'test'):  # run normally\n",
        "        test(opt.data,\n",
        "             opt.weights,\n",
        "             opt.batch_size,\n",
        "             opt.img_size,\n",
        "             opt.conf_thres,\n",
        "             opt.iou_thres,\n",
        "             opt.save_json,\n",
        "             opt.single_cls,\n",
        "             opt.augment,\n",
        "             opt.verbose,\n",
        "             save_txt=opt.save_txt | opt.save_hybrid,\n",
        "             save_hybrid=opt.save_hybrid,\n",
        "             save_conf=opt.save_conf,\n",
        "             trace=not opt.no_trace,\n",
        "             v5_metric=opt.v5_metric\n",
        "             )\n",
        "\n",
        "    elif opt.task == 'speed':  # speed benchmarks\n",
        "        for w in opt.weights:\n",
        "            test(opt.data, w, opt.batch_size, opt.img_size, 0.25, 0.45, save_json=False, plots=False, v5_metric=opt.v5_metric)\n",
        "\n",
        "    elif opt.task == 'study':  # run over a range of settings and save/plot\n",
        "        # python test.py --task study --data coco.yaml --iou 0.65 --weights yolov7.pt\n",
        "        x = list(range(256, 1536 + 128, 128))  # x axis (image sizes)\n",
        "        for w in opt.weights:\n",
        "            f = f'study_{Path(opt.data).stem}_{Path(w).stem}.txt'  # filename to save to\n",
        "            y = []  # y axis\n",
        "            for i in x:  # img-size\n",
        "                print(f'\\nRunning {f} point {i}...')\n",
        "                r, _, t = test(opt.data, w, opt.batch_size, i, opt.conf_thres, opt.iou_thres, opt.save_json,\n",
        "                               plots=False, v5_metric=opt.v5_metric)\n",
        "                y.append(r + t)  # results and times\n",
        "            np.savetxt(f, y, fmt='%10.4g')  # save\n",
        "        os.system('zip -r study.zip study_*.txt')\n",
        "        plot_study_txt(x=x)  # plot\n"
      ],
      "metadata": {
        "id": "g4V4e8-M5nMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# 6. **Experimental tests and evaluations**\n",
        "\n",
        "\n",
        "Here you must implement your code for training, testing and evaluating your solution. For this, the following code blocks (*E1*, *E2*, and *E3*) are mandatory:\n",
        "\n",
        "  - *E1* - Training the models. Implement code to call the dataloaders implemented for training your models.  Make routines to test different parameters of your models. Plot graphs that illustrate how parameters impact model training. Compare. Train and select a model for each city (A and B) and justify. You should use half (50%) of the samples from each dataset for training and leave the other half for testing (50%).\n",
        "\n",
        "[top](#scrollTo=4i5afvUbhmGo)"
      ],
      "metadata": {
        "id": "3RBW58of0ZDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import logging\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "from copy import deepcopy\n",
        "from pathlib import Path\n",
        "from threading import Thread\n",
        "\n",
        "import numpy as np\n",
        "import torch.distributed as dist\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "import torch.utils.data\n",
        "import yaml\n",
        "from torch.cuda import amp\n",
        "from torch.nn.parallel import DistributedDataParallel as DDP\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from tqdm import tqdm\n",
        "\n",
        "import test  # import test.py to get mAP after each epoch\n",
        "from models.experimental import attempt_load\n",
        "from models.yolo import Model\n",
        "from utils.autoanchor import check_anchors\n",
        "from utils.datasets import create_dataloader\n",
        "from utils.general import labels_to_class_weights, increment_path, labels_to_image_weights, init_seeds, \\\n",
        "    fitness, strip_optimizer, get_latest_run, check_dataset, check_file, check_git_status, check_img_size, \\\n",
        "    check_requirements, print_mutation, set_logging, one_cycle, colorstr\n",
        "from utils.google_utils import attempt_download\n",
        "from utils.loss import ComputeLoss, ComputeLossOTA\n",
        "from utils.plots import plot_images, plot_labels, plot_results, plot_evolution\n",
        "from utils.torch_utils import ModelEMA, select_device, intersect_dicts, torch_distributed_zero_first, is_parallel\n",
        "from utils.wandb_logging.wandb_utils import WandbLogger, check_wandb_resume\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "def train(hyp, opt, device, tb_writer=None):\n",
        "    logger.info(colorstr('hyperparameters: ') + ', '.join(f'{k}={v}' for k, v in hyp.items()))\n",
        "    save_dir, epochs, batch_size, total_batch_size, weights, rank, freeze = \\\n",
        "        Path(opt.save_dir), opt.epochs, opt.batch_size, opt.total_batch_size, opt.weights, opt.global_rank, opt.freeze\n",
        "\n",
        "    # Directories\n",
        "    wdir = save_dir / 'weights'\n",
        "    wdir.mkdir(parents=True, exist_ok=True)  # make dir\n",
        "    last = wdir / 'last.pt'\n",
        "    best = wdir / 'best.pt'\n",
        "    results_file = save_dir / 'results.txt'\n",
        "\n",
        "    # Save run settings\n",
        "    with open(save_dir / 'hyp.yaml', 'w') as f:\n",
        "        yaml.dump(hyp, f, sort_keys=False)\n",
        "    with open(save_dir / 'opt.yaml', 'w') as f:\n",
        "        yaml.dump(vars(opt), f, sort_keys=False)\n",
        "\n",
        "    # Configure\n",
        "    plots = not opt.evolve  # create plots\n",
        "    cuda = device.type != 'cpu'\n",
        "    init_seeds(2 + rank)\n",
        "    with open(opt.data) as f:\n",
        "        data_dict = yaml.load(f, Loader=yaml.SafeLoader)  # data dict\n",
        "    is_coco = opt.data.endswith('coco.yaml')\n",
        "\n",
        "    # Logging- Doing this before checking the dataset. Might update data_dict\n",
        "    loggers = {'wandb': None}  # loggers dict\n",
        "    if rank in [-1, 0]:\n",
        "        opt.hyp = hyp  # add hyperparameters\n",
        "        run_id = torch.load(weights, map_location=device).get('wandb_id') if weights.endswith('.pt') and os.path.isfile(weights) else None\n",
        "        wandb_logger = WandbLogger(opt, Path(opt.save_dir).stem, run_id, data_dict)\n",
        "        loggers['wandb'] = wandb_logger.wandb\n",
        "        data_dict = wandb_logger.data_dict\n",
        "        if wandb_logger.wandb:\n",
        "            weights, epochs, hyp = opt.weights, opt.epochs, opt.hyp  # WandbLogger might update weights, epochs if resuming\n",
        "\n",
        "    nc = 1 if opt.single_cls else int(data_dict['nc'])  # number of classes\n",
        "    names = ['item'] if opt.single_cls and len(data_dict['names']) != 1 else data_dict['names']  # class names\n",
        "    assert len(names) == nc, '%g names found for nc=%g dataset in %s' % (len(names), nc, opt.data)  # check\n",
        "\n",
        "    # Model\n",
        "    pretrained = weights.endswith('.pt')\n",
        "    if pretrained:\n",
        "        with torch_distributed_zero_first(rank):\n",
        "            attempt_download(weights)  # download if not found locally\n",
        "        ckpt = torch.load(weights, map_location=device)  # load checkpoint\n",
        "        model = Model(opt.cfg or ckpt['model'].yaml, ch=3, nc=nc, anchors=hyp.get('anchors')).to(device)  # create\n",
        "        exclude = ['anchor'] if (opt.cfg or hyp.get('anchors')) and not opt.resume else []  # exclude keys\n",
        "        state_dict = ckpt['model'].float().state_dict()  # to FP32\n",
        "        state_dict = intersect_dicts(state_dict, model.state_dict(), exclude=exclude)  # intersect\n",
        "        model.load_state_dict(state_dict, strict=False)  # load\n",
        "        logger.info('Transferred %g/%g items from %s' % (len(state_dict), len(model.state_dict()), weights))  # report\n",
        "    else:\n",
        "        model = Model(opt.cfg, ch=3, nc=nc, anchors=hyp.get('anchors')).to(device)  # create\n",
        "    with torch_distributed_zero_first(rank):\n",
        "        check_dataset(data_dict)  # check\n",
        "    train_path = data_dict['train']\n",
        "    test_path = data_dict['val']\n",
        "\n",
        "    # Freeze\n",
        "    freeze = [f'model.{x}.' for x in (freeze if len(freeze) > 1 else range(freeze[0]))]  # parameter names to freeze (full or partial)\n",
        "    for k, v in model.named_parameters():\n",
        "        v.requires_grad = True  # train all layers\n",
        "        if any(x in k for x in freeze):\n",
        "            print('freezing %s' % k)\n",
        "            v.requires_grad = False\n",
        "\n",
        "    # Optimizer\n",
        "    nbs = 64  # nominal batch size\n",
        "    accumulate = max(round(nbs / total_batch_size), 1)  # accumulate loss before optimizing\n",
        "    hyp['weight_decay'] *= total_batch_size * accumulate / nbs  # scale weight_decay\n",
        "    logger.info(f\"Scaled weight_decay = {hyp['weight_decay']}\")\n",
        "\n",
        "    pg0, pg1, pg2 = [], [], []  # optimizer parameter groups\n",
        "    for k, v in model.named_modules():\n",
        "        if hasattr(v, 'bias') and isinstance(v.bias, nn.Parameter):\n",
        "            pg2.append(v.bias)  # biases\n",
        "        if isinstance(v, nn.BatchNorm2d):\n",
        "            pg0.append(v.weight)  # no decay\n",
        "        elif hasattr(v, 'weight') and isinstance(v.weight, nn.Parameter):\n",
        "            pg1.append(v.weight)  # apply decay\n",
        "        if hasattr(v, 'im'):\n",
        "            if hasattr(v.im, 'implicit'):\n",
        "                pg0.append(v.im.implicit)\n",
        "            else:\n",
        "                for iv in v.im:\n",
        "                    pg0.append(iv.implicit)\n",
        "        if hasattr(v, 'imc'):\n",
        "            if hasattr(v.imc, 'implicit'):\n",
        "                pg0.append(v.imc.implicit)\n",
        "            else:\n",
        "                for iv in v.imc:\n",
        "                    pg0.append(iv.implicit)\n",
        "        if hasattr(v, 'imb'):\n",
        "            if hasattr(v.imb, 'implicit'):\n",
        "                pg0.append(v.imb.implicit)\n",
        "            else:\n",
        "                for iv in v.imb:\n",
        "                    pg0.append(iv.implicit)\n",
        "        if hasattr(v, 'imo'):\n",
        "            if hasattr(v.imo, 'implicit'):\n",
        "                pg0.append(v.imo.implicit)\n",
        "            else:\n",
        "                for iv in v.imo:\n",
        "                    pg0.append(iv.implicit)\n",
        "        if hasattr(v, 'ia'):\n",
        "            if hasattr(v.ia, 'implicit'):\n",
        "                pg0.append(v.ia.implicit)\n",
        "            else:\n",
        "                for iv in v.ia:\n",
        "                    pg0.append(iv.implicit)\n",
        "        if hasattr(v, 'attn'):\n",
        "            if hasattr(v.attn, 'logit_scale'):\n",
        "                pg0.append(v.attn.logit_scale)\n",
        "            if hasattr(v.attn, 'q_bias'):\n",
        "                pg0.append(v.attn.q_bias)\n",
        "            if hasattr(v.attn, 'v_bias'):\n",
        "                pg0.append(v.attn.v_bias)\n",
        "            if hasattr(v.attn, 'relative_position_bias_table'):\n",
        "                pg0.append(v.attn.relative_position_bias_table)\n",
        "        if hasattr(v, 'rbr_dense'):\n",
        "            if hasattr(v.rbr_dense, 'weight_rbr_origin'):\n",
        "                pg0.append(v.rbr_dense.weight_rbr_origin)\n",
        "            if hasattr(v.rbr_dense, 'weight_rbr_avg_conv'):\n",
        "                pg0.append(v.rbr_dense.weight_rbr_avg_conv)\n",
        "            if hasattr(v.rbr_dense, 'weight_rbr_pfir_conv'):\n",
        "                pg0.append(v.rbr_dense.weight_rbr_pfir_conv)\n",
        "            if hasattr(v.rbr_dense, 'weight_rbr_1x1_kxk_idconv1'):\n",
        "                pg0.append(v.rbr_dense.weight_rbr_1x1_kxk_idconv1)\n",
        "            if hasattr(v.rbr_dense, 'weight_rbr_1x1_kxk_conv2'):\n",
        "                pg0.append(v.rbr_dense.weight_rbr_1x1_kxk_conv2)\n",
        "            if hasattr(v.rbr_dense, 'weight_rbr_gconv_dw'):\n",
        "                pg0.append(v.rbr_dense.weight_rbr_gconv_dw)\n",
        "            if hasattr(v.rbr_dense, 'weight_rbr_gconv_pw'):\n",
        "                pg0.append(v.rbr_dense.weight_rbr_gconv_pw)\n",
        "            if hasattr(v.rbr_dense, 'vector'):\n",
        "                pg0.append(v.rbr_dense.vector)\n",
        "\n",
        "    if opt.adam:\n",
        "        optimizer = optim.Adam(pg0, lr=hyp['lr0'], betas=(hyp['momentum'], 0.999))  # adjust beta1 to momentum\n",
        "    else:\n",
        "        optimizer = optim.SGD(pg0, lr=hyp['lr0'], momentum=hyp['momentum'], nesterov=True)\n",
        "\n",
        "    optimizer.add_param_group({'params': pg1, 'weight_decay': hyp['weight_decay']})  # add pg1 with weight_decay\n",
        "    optimizer.add_param_group({'params': pg2})  # add pg2 (biases)\n",
        "    logger.info('Optimizer groups: %g .bias, %g conv.weight, %g other' % (len(pg2), len(pg1), len(pg0)))\n",
        "    del pg0, pg1, pg2\n",
        "\n",
        "    # Scheduler https://arxiv.org/pdf/1812.01187.pdf\n",
        "    # https://pytorch.org/docs/stable/_modules/torch/optim/lr_scheduler.html#OneCycleLR\n",
        "    if opt.linear_lr:\n",
        "        lf = lambda x: (1 - x / (epochs - 1)) * (1.0 - hyp['lrf']) + hyp['lrf']  # linear\n",
        "    else:\n",
        "        lf = one_cycle(1, hyp['lrf'], epochs)  # cosine 1->hyp['lrf']\n",
        "    scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lf)\n",
        "    # plot_lr_scheduler(optimizer, scheduler, epochs)\n",
        "\n",
        "    # EMA\n",
        "    ema = ModelEMA(model) if rank in [-1, 0] else None\n",
        "\n",
        "    # Resume\n",
        "    start_epoch, best_fitness = 0, 0.0\n",
        "    if pretrained:\n",
        "        # Optimizer\n",
        "        if ckpt['optimizer'] is not None:\n",
        "            optimizer.load_state_dict(ckpt['optimizer'])\n",
        "            best_fitness = ckpt['best_fitness']\n",
        "\n",
        "        # EMA\n",
        "        if ema and ckpt.get('ema'):\n",
        "            ema.ema.load_state_dict(ckpt['ema'].float().state_dict())\n",
        "            ema.updates = ckpt['updates']\n",
        "\n",
        "        # Results\n",
        "        if ckpt.get('training_results') is not None:\n",
        "            results_file.write_text(ckpt['training_results'])  # write results.txt\n",
        "\n",
        "        # Epochs\n",
        "        start_epoch = ckpt['epoch'] + 1\n",
        "        if opt.resume:\n",
        "            assert start_epoch > 0, '%s training to %g epochs is finished, nothing to resume.' % (weights, epochs)\n",
        "        if epochs < start_epoch:\n",
        "            logger.info('%s has been trained for %g epochs. Fine-tuning for %g additional epochs.' %\n",
        "                        (weights, ckpt['epoch'], epochs))\n",
        "            epochs += ckpt['epoch']  # finetune additional epochs\n",
        "\n",
        "        del ckpt, state_dict\n",
        "\n",
        "    # Image sizes\n",
        "    gs = max(int(model.stride.max()), 32)  # grid size (max stride)\n",
        "    nl = model.model[-1].nl  # number of detection layers (used for scaling hyp['obj'])\n",
        "    imgsz, imgsz_test = [check_img_size(x, gs) for x in opt.img_size]  # verify imgsz are gs-multiples\n",
        "\n",
        "    # DP mode\n",
        "    if cuda and rank == -1 and torch.cuda.device_count() > 1:\n",
        "        model = torch.nn.DataParallel(model)\n",
        "\n",
        "    # SyncBatchNorm\n",
        "    if opt.sync_bn and cuda and rank != -1:\n",
        "        model = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model).to(device)\n",
        "        logger.info('Using SyncBatchNorm()')\n",
        "\n",
        "    # Trainloader\n",
        "    dataloader, dataset = create_dataloader(train_path, imgsz, batch_size, gs, opt,\n",
        "                                            hyp=hyp, augment=True, cache=opt.cache_images, rect=opt.rect, rank=rank,\n",
        "                                            world_size=opt.world_size, workers=opt.workers,\n",
        "                                            image_weights=opt.image_weights, quad=opt.quad, prefix=colorstr('train: '))\n",
        "    mlc = np.concatenate(dataset.labels, 0)[:, 0].max()  # max label class\n",
        "    nb = len(dataloader)  # number of batches\n",
        "    assert mlc < nc, 'Label class %g exceeds nc=%g in %s. Possible class labels are 0-%g' % (mlc, nc, opt.data, nc - 1)\n",
        "\n",
        "    # Process 0\n",
        "    if rank in [-1, 0]:\n",
        "        testloader = create_dataloader(test_path, imgsz_test, batch_size * 2, gs, opt,  # testloader\n",
        "                                       hyp=hyp, cache=opt.cache_images and not opt.notest, rect=True, rank=-1,\n",
        "                                       world_size=opt.world_size, workers=opt.workers,\n",
        "                                       pad=0.5, prefix=colorstr('val: '))[0]\n",
        "\n",
        "        if not opt.resume:\n",
        "            labels = np.concatenate(dataset.labels, 0)\n",
        "            c = torch.tensor(labels[:, 0])  # classes\n",
        "            # cf = torch.bincount(c.long(), minlength=nc) + 1.  # frequency\n",
        "            # model._initialize_biases(cf.to(device))\n",
        "            if plots:\n",
        "                #plot_labels(labels, names, save_dir, loggers)\n",
        "                if tb_writer:\n",
        "                    tb_writer.add_histogram('classes', c, 0)\n",
        "\n",
        "            # Anchors\n",
        "            if not opt.noautoanchor:\n",
        "                check_anchors(dataset, model=model, thr=hyp['anchor_t'], imgsz=imgsz)\n",
        "            model.half().float()  # pre-reduce anchor precision\n",
        "\n",
        "    # DDP mode\n",
        "    if cuda and rank != -1:\n",
        "        model = DDP(model, device_ids=[opt.local_rank], output_device=opt.local_rank,\n",
        "                    # nn.MultiheadAttention incompatibility with DDP https://github.com/pytorch/pytorch/issues/26698\n",
        "                    find_unused_parameters=any(isinstance(layer, nn.MultiheadAttention) for layer in model.modules()))\n",
        "\n",
        "    # Model parameters\n",
        "    hyp['box'] *= 3. / nl  # scale to layers\n",
        "    hyp['cls'] *= nc / 80. * 3. / nl  # scale to classes and layers\n",
        "    hyp['obj'] *= (imgsz / 640) ** 2 * 3. / nl  # scale to image size and layers\n",
        "    hyp['label_smoothing'] = opt.label_smoothing\n",
        "    model.nc = nc  # attach number of classes to model\n",
        "    model.hyp = hyp  # attach hyperparameters to model\n",
        "    model.gr = 1.0  # iou loss ratio (obj_loss = 1.0 or iou)\n",
        "    model.class_weights = labels_to_class_weights(dataset.labels, nc).to(device) * nc  # attach class weights\n",
        "    model.names = names\n",
        "\n",
        "    # Start training\n",
        "    t0 = time.time()\n",
        "    nw = max(round(hyp['warmup_epochs'] * nb), 1000)  # number of warmup iterations, max(3 epochs, 1k iterations)\n",
        "    # nw = min(nw, (epochs - start_epoch) / 2 * nb)  # limit warmup to < 1/2 of training\n",
        "    maps = np.zeros(nc)  # mAP per class\n",
        "    results = (0, 0, 0, 0, 0, 0, 0)  # P, R, mAP@.5, mAP@.5-.95, val_loss(box, obj, cls)\n",
        "    scheduler.last_epoch = start_epoch - 1  # do not move\n",
        "    scaler = amp.GradScaler(enabled=cuda)\n",
        "    compute_loss_ota = ComputeLossOTA(model)  # init loss class\n",
        "    compute_loss = ComputeLoss(model)  # init loss class\n",
        "    logger.info(f'Image sizes {imgsz} train, {imgsz_test} test\\n'\n",
        "                f'Using {dataloader.num_workers} dataloader workers\\n'\n",
        "                f'Logging results to {save_dir}\\n'\n",
        "                f'Starting training for {epochs} epochs...')\n",
        "    torch.save(model, wdir / 'init.pt')\n",
        "    for epoch in range(start_epoch, epochs):  # epoch ------------------------------------------------------------------\n",
        "        model.train()\n",
        "\n",
        "        # Update image weights (optional)\n",
        "        if opt.image_weights:\n",
        "            # Generate indices\n",
        "            if rank in [-1, 0]:\n",
        "                cw = model.class_weights.cpu().numpy() * (1 - maps) ** 2 / nc  # class weights\n",
        "                iw = labels_to_image_weights(dataset.labels, nc=nc, class_weights=cw)  # image weights\n",
        "                dataset.indices = random.choices(range(dataset.n), weights=iw, k=dataset.n)  # rand weighted idx\n",
        "            # Broadcast if DDP\n",
        "            if rank != -1:\n",
        "                indices = (torch.tensor(dataset.indices) if rank == 0 else torch.zeros(dataset.n)).int()\n",
        "                dist.broadcast(indices, 0)\n",
        "                if rank != 0:\n",
        "                    dataset.indices = indices.cpu().numpy()\n",
        "\n",
        "        # Update mosaic border\n",
        "        # b = int(random.uniform(0.25 * imgsz, 0.75 * imgsz + gs) // gs * gs)\n",
        "        # dataset.mosaic_border = [b - imgsz, -b]  # height, width borders\n",
        "\n",
        "        mloss = torch.zeros(4, device=device)  # mean losses\n",
        "        if rank != -1:\n",
        "            dataloader.sampler.set_epoch(epoch)\n",
        "        pbar = enumerate(dataloader)\n",
        "        logger.info(('\\n' + '%10s' * 8) % ('Epoch', 'gpu_mem', 'box', 'obj', 'cls', 'total', 'labels', 'img_size'))\n",
        "        if rank in [-1, 0]:\n",
        "            pbar = tqdm(pbar, total=nb)  # progress bar\n",
        "        optimizer.zero_grad()\n",
        "        for i, (imgs, targets, paths, _) in pbar:  # batch -------------------------------------------------------------\n",
        "            ni = i + nb * epoch  # number integrated batches (since train start)\n",
        "            imgs = imgs.to(device, non_blocking=True).float() / 255.0  # uint8 to float32, 0-255 to 0.0-1.0\n",
        "\n",
        "            # Warmup\n",
        "            if ni <= nw:\n",
        "                xi = [0, nw]  # x interp\n",
        "                # model.gr = np.interp(ni, xi, [0.0, 1.0])  # iou loss ratio (obj_loss = 1.0 or iou)\n",
        "                accumulate = max(1, np.interp(ni, xi, [1, nbs / total_batch_size]).round())\n",
        "                for j, x in enumerate(optimizer.param_groups):\n",
        "                    # bias lr falls from 0.1 to lr0, all other lrs rise from 0.0 to lr0\n",
        "                    x['lr'] = np.interp(ni, xi, [hyp['warmup_bias_lr'] if j == 2 else 0.0, x['initial_lr'] * lf(epoch)])\n",
        "                    if 'momentum' in x:\n",
        "                        x['momentum'] = np.interp(ni, xi, [hyp['warmup_momentum'], hyp['momentum']])\n",
        "\n",
        "            # Multi-scale\n",
        "            if opt.multi_scale:\n",
        "                sz = random.randrange(imgsz * 0.5, imgsz * 1.5 + gs) // gs * gs  # size\n",
        "                sf = sz / max(imgs.shape[2:])  # scale factor\n",
        "                if sf != 1:\n",
        "                    ns = [math.ceil(x * sf / gs) * gs for x in imgs.shape[2:]]  # new shape (stretched to gs-multiple)\n",
        "                    imgs = F.interpolate(imgs, size=ns, mode='bilinear', align_corners=False)\n",
        "\n",
        "            # Forward\n",
        "            with amp.autocast(enabled=cuda):\n",
        "                pred = model(imgs)  # forward\n",
        "                if 'loss_ota' not in hyp or hyp['loss_ota'] == 1:\n",
        "                    loss, loss_items = compute_loss_ota(pred, targets.to(device), imgs)  # loss scaled by batch_size\n",
        "                else:\n",
        "                    loss, loss_items = compute_loss(pred, targets.to(device))  # loss scaled by batch_size\n",
        "                if rank != -1:\n",
        "                    loss *= opt.world_size  # gradient averaged between devices in DDP mode\n",
        "                if opt.quad:\n",
        "                    loss *= 4.\n",
        "\n",
        "            # Backward\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "            # Optimize\n",
        "            if ni % accumulate == 0:\n",
        "                scaler.step(optimizer)  # optimizer.step\n",
        "                scaler.update()\n",
        "                optimizer.zero_grad()\n",
        "                if ema:\n",
        "                    ema.update(model)\n",
        "\n",
        "            # Print\n",
        "            if rank in [-1, 0]:\n",
        "                mloss = (mloss * i + loss_items) / (i + 1)  # update mean losses\n",
        "                mem = '%.3gG' % (torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0)  # (GB)\n",
        "                s = ('%10s' * 2 + '%10.4g' * 6) % (\n",
        "                    '%g/%g' % (epoch, epochs - 1), mem, *mloss, targets.shape[0], imgs.shape[-1])\n",
        "                pbar.set_description(s)\n",
        "\n",
        "                # Plot\n",
        "                if plots and ni < 10:\n",
        "                    f = save_dir / f'train_batch{ni}.jpg'  # filename\n",
        "                    Thread(target=plot_images, args=(imgs, targets, paths, f), daemon=True).start()\n",
        "                    # if tb_writer:\n",
        "                    #     tb_writer.add_image(f, result, dataformats='HWC', global_step=epoch)\n",
        "                    #     tb_writer.add_graph(torch.jit.trace(model, imgs, strict=False), [])  # add model graph\n",
        "                elif plots and ni == 10 and wandb_logger.wandb:\n",
        "                    wandb_logger.log({\"Mosaics\": [wandb_logger.wandb.Image(str(x), caption=x.name) for x in\n",
        "                                                  save_dir.glob('train*.jpg') if x.exists()]})\n",
        "\n",
        "            # end batch ------------------------------------------------------------------------------------------------\n",
        "        # end epoch ----------------------------------------------------------------------------------------------------\n",
        "\n",
        "        # Scheduler\n",
        "        lr = [x['lr'] for x in optimizer.param_groups]  # for tensorboard\n",
        "        scheduler.step()\n",
        "\n",
        "        # DDP process 0 or single-GPU\n",
        "        if rank in [-1, 0]:\n",
        "            # mAP\n",
        "            ema.update_attr(model, include=['yaml', 'nc', 'hyp', 'gr', 'names', 'stride', 'class_weights'])\n",
        "            final_epoch = epoch + 1 == epochs\n",
        "            if not opt.notest or final_epoch:  # Calculate mAP\n",
        "                wandb_logger.current_epoch = epoch + 1\n",
        "                results, maps, times = test.test(data_dict,\n",
        "                                                 batch_size=batch_size * 2,\n",
        "                                                 imgsz=imgsz_test,\n",
        "                                                 model=ema.ema,\n",
        "                                                 single_cls=opt.single_cls,\n",
        "                                                 dataloader=testloader,\n",
        "                                                 save_dir=save_dir,\n",
        "                                                 verbose=nc < 50 and final_epoch,\n",
        "                                                 plots=plots and final_epoch,\n",
        "                                                 wandb_logger=wandb_logger,\n",
        "                                                 compute_loss=compute_loss,\n",
        "                                                 is_coco=is_coco,\n",
        "                                                 v5_metric=opt.v5_metric)\n",
        "\n",
        "            # Write\n",
        "            with open(results_file, 'a') as f:\n",
        "                f.write(s + '%10.4g' * 7 % results + '\\n')  # append metrics, val_loss\n",
        "            if len(opt.name) and opt.bucket:\n",
        "                os.system('gsutil cp %s gs://%s/results/results%s.txt' % (results_file, opt.bucket, opt.name))\n",
        "\n",
        "            # Log\n",
        "            tags = ['train/box_loss', 'train/obj_loss', 'train/cls_loss',  # train loss\n",
        "                    'metrics/precision', 'metrics/recall', 'metrics/mAP_0.5', 'metrics/mAP_0.5:0.95',\n",
        "                    'val/box_loss', 'val/obj_loss', 'val/cls_loss',  # val loss\n",
        "                    'x/lr0', 'x/lr1', 'x/lr2']  # params\n",
        "            for x, tag in zip(list(mloss[:-1]) + list(results) + lr, tags):\n",
        "                if tb_writer:\n",
        "                    tb_writer.add_scalar(tag, x, epoch)  # tensorboard\n",
        "                if wandb_logger.wandb:\n",
        "                    wandb_logger.log({tag: x})  # W&B\n",
        "\n",
        "            # Update best mAP\n",
        "            fi = fitness(np.array(results).reshape(1, -1))  # weighted combination of [P, R, mAP@.5, mAP@.5-.95]\n",
        "            if fi > best_fitness:\n",
        "                best_fitness = fi\n",
        "            wandb_logger.end_epoch(best_result=best_fitness == fi)\n",
        "\n",
        "            # Save model\n",
        "            if (not opt.nosave) or (final_epoch and not opt.evolve):  # if save\n",
        "                ckpt = {'epoch': epoch,\n",
        "                        'best_fitness': best_fitness,\n",
        "                        'training_results': results_file.read_text(),\n",
        "                        'model': deepcopy(model.module if is_parallel(model) else model).half(),\n",
        "                        'ema': deepcopy(ema.ema).half(),\n",
        "                        'updates': ema.updates,\n",
        "                        'optimizer': optimizer.state_dict(),\n",
        "                        'wandb_id': wandb_logger.wandb_run.id if wandb_logger.wandb else None}\n",
        "\n",
        "                # Save last, best and delete\n",
        "                torch.save(ckpt, last)\n",
        "                if best_fitness == fi:\n",
        "                    torch.save(ckpt, best)\n",
        "                if (best_fitness == fi) and (epoch >= 200):\n",
        "                    torch.save(ckpt, wdir / 'best_{:03d}.pt'.format(epoch))\n",
        "                if epoch == 0:\n",
        "                    torch.save(ckpt, wdir / 'epoch_{:03d}.pt'.format(epoch))\n",
        "                elif ((epoch+1) % 25) == 0:\n",
        "                    torch.save(ckpt, wdir / 'epoch_{:03d}.pt'.format(epoch))\n",
        "                elif epoch >= (epochs-5):\n",
        "                    torch.save(ckpt, wdir / 'epoch_{:03d}.pt'.format(epoch))\n",
        "                if wandb_logger.wandb:\n",
        "                    if ((epoch + 1) % opt.save_period == 0 and not final_epoch) and opt.save_period != -1:\n",
        "                        wandb_logger.log_model(\n",
        "                            last.parent, opt, epoch, fi, best_model=best_fitness == fi)\n",
        "                del ckpt\n",
        "\n",
        "        # end epoch ----------------------------------------------------------------------------------------------------\n",
        "    # end training\n",
        "    if rank in [-1, 0]:\n",
        "        # Plots\n",
        "        if plots:\n",
        "            plot_results(save_dir=save_dir)  # save as results.png\n",
        "            if wandb_logger.wandb:\n",
        "                files = ['results.png', 'confusion_matrix.png', *[f'{x}_curve.png' for x in ('F1', 'PR', 'P', 'R')]]\n",
        "                wandb_logger.log({\"Results\": [wandb_logger.wandb.Image(str(save_dir / f), caption=f) for f in files\n",
        "                                              if (save_dir / f).exists()]})\n",
        "        # Test best.pt\n",
        "        logger.info('%g epochs completed in %.3f hours.\\n' % (epoch - start_epoch + 1, (time.time() - t0) / 3600))\n",
        "        if opt.data.endswith('coco.yaml') and nc == 80:  # if COCO\n",
        "            for m in (last, best) if best.exists() else (last):  # speed, mAP tests\n",
        "                results, _, _ = test.test(opt.data,\n",
        "                                          batch_size=batch_size * 2,\n",
        "                                          imgsz=imgsz_test,\n",
        "                                          conf_thres=0.001,\n",
        "                                          iou_thres=0.7,\n",
        "                                          model=attempt_load(m, device).half(),\n",
        "                                          single_cls=opt.single_cls,\n",
        "                                          dataloader=testloader,\n",
        "                                          save_dir=save_dir,\n",
        "                                          save_json=True,\n",
        "                                          plots=False,\n",
        "                                          is_coco=is_coco,\n",
        "                                          v5_metric=opt.v5_metric)\n",
        "\n",
        "        # Strip optimizers\n",
        "        final = best if best.exists() else last  # final model\n",
        "        for f in last, best:\n",
        "            if f.exists():\n",
        "                strip_optimizer(f)  # strip optimizers\n",
        "        if opt.bucket:\n",
        "            os.system(f'gsutil cp {final} gs://{opt.bucket}/weights')  # upload\n",
        "        if wandb_logger.wandb and not opt.evolve:  # Log the stripped model\n",
        "            wandb_logger.wandb.log_artifact(str(final), type='model',\n",
        "                                            name='run_' + wandb_logger.wandb_run.id + '_model',\n",
        "                                            aliases=['last', 'best', 'stripped'])\n",
        "        wandb_logger.finish_run()\n",
        "    else:\n",
        "        dist.destroy_process_group()\n",
        "    torch.cuda.empty_cache()\n",
        "    return results\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--weights', type=str, default='yolo7.pt', help='initial weights path')\n",
        "    parser.add_argument('--cfg', type=str, default='', help='model.yaml path')\n",
        "    parser.add_argument('--data', type=str, default='data/coco.yaml', help='data.yaml path')\n",
        "    parser.add_argument('--hyp', type=str, default='data/hyp.scratch.p5.yaml', help='hyperparameters path')\n",
        "    parser.add_argument('--epochs', type=int, default=300)\n",
        "    parser.add_argument('--batch-size', type=int, default=16, help='total batch size for all GPUs')\n",
        "    parser.add_argument('--img-size', nargs='+', type=int, default=[640, 640], help='[train, test] image sizes')\n",
        "    parser.add_argument('--rect', action='store_true', help='rectangular training')\n",
        "    parser.add_argument('--resume', nargs='?', const=True, default=False, help='resume most recent training')\n",
        "    parser.add_argument('--nosave', action='store_true', help='only save final checkpoint')\n",
        "    parser.add_argument('--notest', action='store_true', help='only test final epoch')\n",
        "    parser.add_argument('--noautoanchor', action='store_true', help='disable autoanchor check')\n",
        "    parser.add_argument('--evolve', action='store_true', help='evolve hyperparameters')\n",
        "    parser.add_argument('--bucket', type=str, default='', help='gsutil bucket')\n",
        "    parser.add_argument('--cache-images', action='store_true', help='cache images for faster training')\n",
        "    parser.add_argument('--image-weights', action='store_true', help='use weighted image selection for training')\n",
        "    parser.add_argument('--device', default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')\n",
        "    parser.add_argument('--multi-scale', action='store_true', help='vary img-size +/- 50%%')\n",
        "    parser.add_argument('--single-cls', action='store_true', help='train multi-class data as single-class')\n",
        "    parser.add_argument('--adam', action='store_true', help='use torch.optim.Adam() optimizer')\n",
        "    parser.add_argument('--sync-bn', action='store_true', help='use SyncBatchNorm, only available in DDP mode')\n",
        "    parser.add_argument('--local_rank', type=int, default=-1, help='DDP parameter, do not modify')\n",
        "    parser.add_argument('--workers', type=int, default=8, help='maximum number of dataloader workers')\n",
        "    parser.add_argument('--project', default='runs/train', help='save to project/name')\n",
        "    parser.add_argument('--entity', default=None, help='W&B entity')\n",
        "    parser.add_argument('--name', default='exp', help='save to project/name')\n",
        "    parser.add_argument('--exist-ok', action='store_true', help='existing project/name ok, do not increment')\n",
        "    parser.add_argument('--quad', action='store_true', help='quad dataloader')\n",
        "    parser.add_argument('--linear-lr', action='store_true', help='linear LR')\n",
        "    parser.add_argument('--label-smoothing', type=float, default=0.0, help='Label smoothing epsilon')\n",
        "    parser.add_argument('--upload_dataset', action='store_true', help='Upload dataset as W&B artifact table')\n",
        "    parser.add_argument('--bbox_interval', type=int, default=-1, help='Set bounding-box image logging interval for W&B')\n",
        "    parser.add_argument('--save_period', type=int, default=-1, help='Log model after every \"save_period\" epoch')\n",
        "    parser.add_argument('--artifact_alias', type=str, default=\"latest\", help='version of dataset artifact to be used')\n",
        "    parser.add_argument('--freeze', nargs='+', type=int, default=[0], help='Freeze layers: backbone of yolov7=50, first3=0 1 2')\n",
        "    parser.add_argument('--v5-metric', action='store_true', help='assume maximum recall as 1.0 in AP calculation')\n",
        "    opt = parser.parse_args()\n",
        "\n",
        "    # Set DDP variables\n",
        "    opt.world_size = int(os.environ['WORLD_SIZE']) if 'WORLD_SIZE' in os.environ else 1\n",
        "    opt.global_rank = int(os.environ['RANK']) if 'RANK' in os.environ else -1\n",
        "    set_logging(opt.global_rank)\n",
        "    #if opt.global_rank in [-1, 0]:\n",
        "    #    check_git_status()\n",
        "    #    check_requirements()\n",
        "\n",
        "    # Resume\n",
        "    wandb_run = check_wandb_resume(opt)\n",
        "    if opt.resume and not wandb_run:  # resume an interrupted run\n",
        "        ckpt = opt.resume if isinstance(opt.resume, str) else get_latest_run()  # specified or most recent path\n",
        "        assert os.path.isfile(ckpt), 'ERROR: --resume checkpoint does not exist'\n",
        "        apriori = opt.global_rank, opt.local_rank\n",
        "        with open(Path(ckpt).parent.parent / 'opt.yaml') as f:\n",
        "            opt = argparse.Namespace(**yaml.load(f, Loader=yaml.SafeLoader))  # replace\n",
        "        opt.cfg, opt.weights, opt.resume, opt.batch_size, opt.global_rank, opt.local_rank = '', ckpt, True, opt.total_batch_size, *apriori  # reinstate\n",
        "        logger.info('Resuming training from %s' % ckpt)\n",
        "    else:\n",
        "        # opt.hyp = opt.hyp or ('hyp.finetune.yaml' if opt.weights else 'hyp.scratch.yaml')\n",
        "        opt.data, opt.cfg, opt.hyp = check_file(opt.data), check_file(opt.cfg), check_file(opt.hyp)  # check files\n",
        "        assert len(opt.cfg) or len(opt.weights), 'either --cfg or --weights must be specified'\n",
        "        opt.img_size.extend([opt.img_size[-1]] * (2 - len(opt.img_size)))  # extend to 2 sizes (train, test)\n",
        "        opt.name = 'evolve' if opt.evolve else opt.name\n",
        "        opt.save_dir = increment_path(Path(opt.project) / opt.name, exist_ok=opt.exist_ok | opt.evolve)  # increment run\n",
        "\n",
        "    # DDP mode\n",
        "    opt.total_batch_size = opt.batch_size\n",
        "    device = select_device(opt.device, batch_size=opt.batch_size)\n",
        "    if opt.local_rank != -1:\n",
        "        assert torch.cuda.device_count() > opt.local_rank\n",
        "        torch.cuda.set_device(opt.local_rank)\n",
        "        device = torch.device('cuda', opt.local_rank)\n",
        "        dist.init_process_group(backend='nccl', init_method='env://')  # distributed backend\n",
        "        assert opt.batch_size % opt.world_size == 0, '--batch-size must be multiple of CUDA device count'\n",
        "        opt.batch_size = opt.total_batch_size // opt.world_size\n",
        "\n",
        "    # Hyperparameters\n",
        "    with open(opt.hyp) as f:\n",
        "        hyp = yaml.load(f, Loader=yaml.SafeLoader)  # load hyps\n",
        "\n",
        "    # Train\n",
        "    logger.info(opt)\n",
        "    if not opt.evolve:\n",
        "        tb_writer = None  # init loggers\n",
        "        if opt.global_rank in [-1, 0]:\n",
        "            prefix = colorstr('tensorboard: ')\n",
        "            logger.info(f\"{prefix}Start with 'tensorboard --logdir {opt.project}', view at http://localhost:6006/\")\n",
        "            tb_writer = SummaryWriter(opt.save_dir)  # Tensorboard\n",
        "        train(hyp, opt, device, tb_writer)\n",
        "\n",
        "    # Evolve hyperparameters (optional)\n",
        "    else:\n",
        "        # Hyperparameter evolution metadata (mutation scale 0-1, lower_limit, upper_limit)\n",
        "        meta = {'lr0': (1, 1e-5, 1e-1),  # initial learning rate (SGD=1E-2, Adam=1E-3)\n",
        "                'lrf': (1, 0.01, 1.0),  # final OneCycleLR learning rate (lr0 * lrf)\n",
        "                'momentum': (0.3, 0.6, 0.98),  # SGD momentum/Adam beta1\n",
        "                'weight_decay': (1, 0.0, 0.001),  # optimizer weight decay\n",
        "                'warmup_epochs': (1, 0.0, 5.0),  # warmup epochs (fractions ok)\n",
        "                'warmup_momentum': (1, 0.0, 0.95),  # warmup initial momentum\n",
        "                'warmup_bias_lr': (1, 0.0, 0.2),  # warmup initial bias lr\n",
        "                'box': (1, 0.02, 0.2),  # box loss gain\n",
        "                'cls': (1, 0.2, 4.0),  # cls loss gain\n",
        "                'cls_pw': (1, 0.5, 2.0),  # cls BCELoss positive_weight\n",
        "                'obj': (1, 0.2, 4.0),  # obj loss gain (scale with pixels)\n",
        "                'obj_pw': (1, 0.5, 2.0),  # obj BCELoss positive_weight\n",
        "                'iou_t': (0, 0.1, 0.7),  # IoU training threshold\n",
        "                'anchor_t': (1, 2.0, 8.0),  # anchor-multiple threshold\n",
        "                'anchors': (2, 2.0, 10.0),  # anchors per output grid (0 to ignore)\n",
        "                'fl_gamma': (0, 0.0, 2.0),  # focal loss gamma (efficientDet default gamma=1.5)\n",
        "                'hsv_h': (1, 0.0, 0.1),  # image HSV-Hue augmentation (fraction)\n",
        "                'hsv_s': (1, 0.0, 0.9),  # image HSV-Saturation augmentation (fraction)\n",
        "                'hsv_v': (1, 0.0, 0.9),  # image HSV-Value augmentation (fraction)\n",
        "                'degrees': (1, 0.0, 45.0),  # image rotation (+/- deg)\n",
        "                'translate': (1, 0.0, 0.9),  # image translation (+/- fraction)\n",
        "                'scale': (1, 0.0, 0.9),  # image scale (+/- gain)\n",
        "                'shear': (1, 0.0, 10.0),  # image shear (+/- deg)\n",
        "                'perspective': (0, 0.0, 0.001),  # image perspective (+/- fraction), range 0-0.001\n",
        "                'flipud': (1, 0.0, 1.0),  # image flip up-down (probability)\n",
        "                'fliplr': (0, 0.0, 1.0),  # image flip left-right (probability)\n",
        "                'mosaic': (1, 0.0, 1.0),  # image mixup (probability)\n",
        "                'mixup': (1, 0.0, 1.0),   # image mixup (probability)\n",
        "                'copy_paste': (1, 0.0, 1.0),  # segment copy-paste (probability)\n",
        "                'paste_in': (1, 0.0, 1.0)}    # segment copy-paste (probability)\n",
        "\n",
        "        with open(opt.hyp, errors='ignore') as f:\n",
        "            hyp = yaml.safe_load(f)  # load hyps dict\n",
        "            if 'anchors' not in hyp:  # anchors commented in hyp.yaml\n",
        "                hyp['anchors'] = 3\n",
        "\n",
        "        assert opt.local_rank == -1, 'DDP mode not implemented for --evolve'\n",
        "        opt.notest, opt.nosave = True, True  # only test/save final epoch\n",
        "        # ei = [isinstance(x, (int, float)) for x in hyp.values()]  # evolvable indices\n",
        "        yaml_file = Path(opt.save_dir) / 'hyp_evolved.yaml'  # save best result here\n",
        "        if opt.bucket:\n",
        "            os.system('gsutil cp gs://%s/evolve.txt .' % opt.bucket)  # download evolve.txt if exists\n",
        "\n",
        "        for _ in range(300):  # generations to evolve\n",
        "            if Path('evolve.txt').exists():  # if evolve.txt exists: select best hyps and mutate\n",
        "                # Select parent(s)\n",
        "                parent = 'single'  # parent selection method: 'single' or 'weighted'\n",
        "                x = np.loadtxt('evolve.txt', ndmin=2)\n",
        "                n = min(5, len(x))  # number of previous results to consider\n",
        "                x = x[np.argsort(-fitness(x))][:n]  # top n mutations\n",
        "                w = fitness(x) - fitness(x).min()  # weights\n",
        "                if parent == 'single' or len(x) == 1:\n",
        "                    # x = x[random.randint(0, n - 1)]  # random selection\n",
        "                    x = x[random.choices(range(n), weights=w)[0]]  # weighted selection\n",
        "                elif parent == 'weighted':\n",
        "                    x = (x * w.reshape(n, 1)).sum(0) / w.sum()  # weighted combination\n",
        "\n",
        "                # Mutate\n",
        "                mp, s = 0.8, 0.2  # mutation probability, sigma\n",
        "                npr = np.random\n",
        "                npr.seed(int(time.time()))\n",
        "                g = np.array([x[0] for x in meta.values()])  # gains 0-1\n",
        "                ng = len(meta)\n",
        "                v = np.ones(ng)\n",
        "                while all(v == 1):  # mutate until a change occurs (prevent duplicates)\n",
        "                    v = (g * (npr.random(ng) < mp) * npr.randn(ng) * npr.random() * s + 1).clip(0.3, 3.0)\n",
        "                for i, k in enumerate(hyp.keys()):  # plt.hist(v.ravel(), 300)\n",
        "                    hyp[k] = float(x[i + 7] * v[i])  # mutate\n",
        "\n",
        "            # Constrain to limits\n",
        "            for k, v in meta.items():\n",
        "                hyp[k] = max(hyp[k], v[1])  # lower limit\n",
        "                hyp[k] = min(hyp[k], v[2])  # upper limit\n",
        "                hyp[k] = round(hyp[k], 5)  # significant digits\n",
        "\n",
        "            # Train mutation\n",
        "            results = train(hyp.copy(), opt, device)\n",
        "\n",
        "            # Write mutation results\n",
        "            print_mutation(hyp.copy(), results, yaml_file, opt.bucket)\n",
        "\n",
        "        # Plot results\n",
        "        plot_evolution(yaml_file)\n",
        "        print(f'Hyperparameter evolution complete. Best results saved as: {yaml_file}\\n'\n",
        "              f'Command to train a new model with these hyperparameters: $ python train.py --hyp {yaml_file}')\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jHWwdXg32BEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  - *E2* - Testing the models in the dataset. You must implement code routines to test the predictive ability of your models using half of each dataset intended for testing. **The model trained in location A must be tested in location A. The model trained in location B must be tested in location B.** Use the evaluation metrics (accuracy, F1-score, AUC, etc) that are most appropriate for your problem. Plot graphs that illustrate the results obtained for each city (A and B). Plot visual examples of correctly (true positive) and incorrectly (false positive) classified samples.\n",
        "\n",
        "[top](#scrollTo=4i5afvUbhmGo)\n"
      ],
      "metadata": {
        "id": "TunTimEv1szf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your codes for E2 here. Create more code cells if needed\n",
        "\n",
        "import argparse\n",
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "from threading import Thread\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import yaml\n",
        "from tqdm import tqdm\n",
        "\n",
        "from models.experimental import attempt_load\n",
        "from utils.datasets import create_dataloader\n",
        "from utils.general import coco80_to_coco91_class, check_dataset, check_file, check_img_size, check_requirements, \\\n",
        "    box_iou, non_max_suppression, scale_coords, xyxy2xywh, xywh2xyxy, set_logging, increment_path, colorstr\n",
        "from utils.metrics import ap_per_class, ConfusionMatrix\n",
        "from utils.plots import plot_images, output_to_target, plot_study_txt\n",
        "from utils.torch_utils import select_device, time_synchronized, TracedModel\n",
        "\n",
        "\n",
        "def test(data,\n",
        "         weights=None,\n",
        "         batch_size=32,\n",
        "         imgsz=640,\n",
        "         conf_thres=0.001,\n",
        "         iou_thres=0.6,  # for NMS\n",
        "         save_json=False,\n",
        "         single_cls=False,\n",
        "         augment=False,\n",
        "         verbose=False,\n",
        "         model=None,\n",
        "         dataloader=None,\n",
        "         save_dir=Path(''),  # for saving images\n",
        "         save_txt=False,  # for auto-labelling\n",
        "         save_hybrid=False,  # for hybrid auto-labelling\n",
        "         save_conf=False,  # save auto-label confidences\n",
        "         plots=True,\n",
        "         wandb_logger=None,\n",
        "         compute_loss=None,\n",
        "         half_precision=True,\n",
        "         trace=False,\n",
        "         is_coco=False,\n",
        "         v5_metric=False):\n",
        "    # Initialize/load model and set device\n",
        "    training = model is not None\n",
        "    if training:  # called by train.py\n",
        "        device = next(model.parameters()).device  # get model device\n",
        "\n",
        "    else:  # called directly\n",
        "        set_logging()\n",
        "        device = select_device(opt.device, batch_size=batch_size)\n",
        "\n",
        "        # Directories\n",
        "        save_dir = Path(increment_path(Path(opt.project) / opt.name, exist_ok=opt.exist_ok))  # increment run\n",
        "        (save_dir / 'labels' if save_txt else save_dir).mkdir(parents=True, exist_ok=True)  # make dir\n",
        "\n",
        "        # Load model\n",
        "        model = attempt_load(weights, map_location=device)  # load FP32 model\n",
        "        gs = max(int(model.stride.max()), 32)  # grid size (max stride)\n",
        "        imgsz = check_img_size(imgsz, s=gs)  # check img_size\n",
        "\n",
        "        if trace:\n",
        "            model = TracedModel(model, device, imgsz)\n",
        "\n",
        "    # Half\n",
        "    half = device.type != 'cpu' and half_precision  # half precision only supported on CUDA\n",
        "    if half:\n",
        "        model.half()\n",
        "\n",
        "    # Configure\n",
        "    model.eval()\n",
        "    if isinstance(data, str):\n",
        "        is_coco = data.endswith('coco.yaml')\n",
        "        with open(data) as f:\n",
        "            data = yaml.load(f, Loader=yaml.SafeLoader)\n",
        "    check_dataset(data)  # check\n",
        "    nc = 1 if single_cls else int(data['nc'])  # number of classes\n",
        "    iouv = torch.linspace(0.5, 0.95, 10).to(device)  # iou vector for mAP@0.5:0.95\n",
        "    niou = iouv.numel()\n",
        "\n",
        "    # Logging\n",
        "    log_imgs = 0\n",
        "    if wandb_logger and wandb_logger.wandb:\n",
        "        log_imgs = min(wandb_logger.log_imgs, 100)\n",
        "    # Dataloader\n",
        "    if not training:\n",
        "        if device.type != 'cpu':\n",
        "            model(torch.zeros(1, 3, imgsz, imgsz).to(device).type_as(next(model.parameters())))  # run once\n",
        "        task = opt.task if opt.task in ('train', 'val', 'test') else 'val'  # path to train/val/test images\n",
        "        dataloader = create_dataloader(data[task], imgsz, batch_size, gs, opt, pad=0.5, rect=True,\n",
        "                                       prefix=colorstr(f'{task}: '))[0]\n",
        "\n",
        "    if v5_metric:\n",
        "        print(\"Testing with YOLOv5 AP metric...\")\n",
        "\n",
        "    seen = 0\n",
        "    confusion_matrix = ConfusionMatrix(nc=nc)\n",
        "    names = {k: v for k, v in enumerate(model.names if hasattr(model, 'names') else model.module.names)}\n",
        "    coco91class = coco80_to_coco91_class()\n",
        "    s = ('%20s' + '%12s' * 6) % ('Class', 'Images', 'Labels', 'P', 'R', 'mAP@.5', 'mAP@.5:.95')\n",
        "    p, r, f1, mp, mr, map50, map, t0, t1 = 0., 0., 0., 0., 0., 0., 0., 0., 0.\n",
        "    loss = torch.zeros(3, device=device)\n",
        "    jdict, stats, ap, ap_class, wandb_images = [], [], [], [], []\n",
        "    for batch_i, (img, targets, paths, shapes) in enumerate(tqdm(dataloader, desc=s)):\n",
        "        img = img.to(device, non_blocking=True)\n",
        "        img = img.half() if half else img.float()  # uint8 to fp16/32\n",
        "        img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
        "        targets = targets.to(device)\n",
        "        nb, _, height, width = img.shape  # batch size, channels, height, width\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # Run model\n",
        "            t = time_synchronized()\n",
        "            out, train_out = model(img, augment=augment)  # inference and training outputs\n",
        "            t0 += time_synchronized() - t\n",
        "\n",
        "            # Compute loss\n",
        "            if compute_loss:\n",
        "                loss += compute_loss([x.float() for x in train_out], targets)[1][:3]  # box, obj, cls\n",
        "\n",
        "            # Run NMS\n",
        "            targets[:, 2:] *= torch.Tensor([width, height, width, height]).to(device)  # to pixels\n",
        "            lb = [targets[targets[:, 0] == i, 1:] for i in range(nb)] if save_hybrid else []  # for autolabelling\n",
        "            t = time_synchronized()\n",
        "            out = non_max_suppression(out, conf_thres=conf_thres, iou_thres=iou_thres, labels=lb, multi_label=True)\n",
        "            t1 += time_synchronized() - t\n",
        "\n",
        "        # Statistics per image\n",
        "        for si, pred in enumerate(out):\n",
        "            labels = targets[targets[:, 0] == si, 1:]\n",
        "            nl = len(labels)\n",
        "            tcls = labels[:, 0].tolist() if nl else []  # target class\n",
        "            path = Path(paths[si])\n",
        "            seen += 1\n",
        "\n",
        "            if len(pred) == 0:\n",
        "                if nl:\n",
        "                    stats.append((torch.zeros(0, niou, dtype=torch.bool), torch.Tensor(), torch.Tensor(), tcls))\n",
        "                continue\n",
        "\n",
        "            # Predictions\n",
        "            predn = pred.clone()\n",
        "            scale_coords(img[si].shape[1:], predn[:, :4], shapes[si][0], shapes[si][1])  # native-space pred\n",
        "\n",
        "            # Append to text file\n",
        "            if save_txt:\n",
        "                gn = torch.tensor(shapes[si][0])[[1, 0, 1, 0]]  # normalization gain whwh\n",
        "                for *xyxy, conf, cls in predn.tolist():\n",
        "                    xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh\n",
        "                    line = (cls, *xywh, conf) if save_conf else (cls, *xywh)  # label format\n",
        "                    with open(save_dir / 'labels' / (path.stem + '.txt'), 'a') as f:\n",
        "                        f.write(('%g ' * len(line)).rstrip() % line + '\\n')\n",
        "\n",
        "            # W&B logging - Media Panel Plots\n",
        "            if len(wandb_images) < log_imgs and wandb_logger.current_epoch > 0:  # Check for test operation\n",
        "                if wandb_logger.current_epoch % wandb_logger.bbox_interval == 0:\n",
        "                    box_data = [{\"position\": {\"minX\": xyxy[0], \"minY\": xyxy[1], \"maxX\": xyxy[2], \"maxY\": xyxy[3]},\n",
        "                                 \"class_id\": int(cls),\n",
        "                                 \"box_caption\": \"%s %.3f\" % (names[cls], conf),\n",
        "                                 \"scores\": {\"class_score\": conf},\n",
        "                                 \"domain\": \"pixel\"} for *xyxy, conf, cls in pred.tolist()]\n",
        "                    boxes = {\"predictions\": {\"box_data\": box_data, \"class_labels\": names}}  # inference-space\n",
        "                    wandb_images.append(wandb_logger.wandb.Image(img[si], boxes=boxes, caption=path.name))\n",
        "            wandb_logger.log_training_progress(predn, path, names) if wandb_logger and wandb_logger.wandb_run else None\n",
        "\n",
        "            # Append to pycocotools JSON dictionary\n",
        "            if save_json:\n",
        "                # [{\"image_id\": 42, \"category_id\": 18, \"bbox\": [258.15, 41.29, 348.26, 243.78], \"score\": 0.236}, ...\n",
        "                image_id = int(path.stem) if path.stem.isnumeric() else path.stem\n",
        "                box = xyxy2xywh(predn[:, :4])  # xywh\n",
        "                box[:, :2] -= box[:, 2:] / 2  # xy center to top-left corner\n",
        "                for p, b in zip(pred.tolist(), box.tolist()):\n",
        "                    jdict.append({'image_id': image_id,\n",
        "                                  'category_id': coco91class[int(p[5])] if is_coco else int(p[5]),\n",
        "                                  'bbox': [round(x, 3) for x in b],\n",
        "                                  'score': round(p[4], 5)})\n",
        "\n",
        "            # Assign all predictions as incorrect\n",
        "            correct = torch.zeros(pred.shape[0], niou, dtype=torch.bool, device=device)\n",
        "            if nl:\n",
        "                detected = []  # target indices\n",
        "                tcls_tensor = labels[:, 0]\n",
        "\n",
        "                # target boxes\n",
        "                tbox = xywh2xyxy(labels[:, 1:5])\n",
        "                scale_coords(img[si].shape[1:], tbox, shapes[si][0], shapes[si][1])  # native-space labels\n",
        "                if plots:\n",
        "                    confusion_matrix.process_batch(predn, torch.cat((labels[:, 0:1], tbox), 1))\n",
        "\n",
        "                # Per target class\n",
        "                for cls in torch.unique(tcls_tensor):\n",
        "                    ti = (cls == tcls_tensor).nonzero(as_tuple=False).view(-1)  # prediction indices\n",
        "                    pi = (cls == pred[:, 5]).nonzero(as_tuple=False).view(-1)  # target indices\n",
        "\n",
        "                    # Search for detections\n",
        "                    if pi.shape[0]:\n",
        "                        # Prediction to target ious\n",
        "                        ious, i = box_iou(predn[pi, :4], tbox[ti]).max(1)  # best ious, indices\n",
        "\n",
        "                        # Append detections\n",
        "                        detected_set = set()\n",
        "                        for j in (ious > iouv[0]).nonzero(as_tuple=False):\n",
        "                            d = ti[i[j]]  # detected target\n",
        "                            if d.item() not in detected_set:\n",
        "                                detected_set.add(d.item())\n",
        "                                detected.append(d)\n",
        "                                correct[pi[j]] = ious[j] > iouv  # iou_thres is 1xn\n",
        "                                if len(detected) == nl:  # all targets already located in image\n",
        "                                    break\n",
        "\n",
        "            # Append statistics (correct, conf, pcls, tcls)\n",
        "            stats.append((correct.cpu(), pred[:, 4].cpu(), pred[:, 5].cpu(), tcls))\n",
        "\n",
        "        # Plot images\n",
        "        if plots and batch_i < 3:\n",
        "            f = save_dir / f'test_batch{batch_i}_labels.jpg'  # labels\n",
        "            Thread(target=plot_images, args=(img, targets, paths, f, names), daemon=True).start()\n",
        "            f = save_dir / f'test_batch{batch_i}_pred.jpg'  # predictions\n",
        "            Thread(target=plot_images, args=(img, output_to_target(out), paths, f, names), daemon=True).start()\n",
        "\n",
        "    # Compute statistics\n",
        "    stats = [np.concatenate(x, 0) for x in zip(*stats)]  # to numpy\n",
        "    if len(stats) and stats[0].any():\n",
        "        p, r, ap, f1, ap_class = ap_per_class(*stats, plot=plots, v5_metric=v5_metric, save_dir=save_dir, names=names)\n",
        "        ap50, ap = ap[:, 0], ap.mean(1)  # AP@0.5, AP@0.5:0.95\n",
        "        mp, mr, map50, map = p.mean(), r.mean(), ap50.mean(), ap.mean()\n",
        "        nt = np.bincount(stats[3].astype(np.int64), minlength=nc)  # number of targets per class\n",
        "    else:\n",
        "        nt = torch.zeros(1)\n",
        "\n",
        "    # Print results\n",
        "    pf = '%20s' + '%12i' * 2 + '%12.3g' * 4  # print format\n",
        "    print(pf % ('all', seen, nt.sum(), mp, mr, map50, map))\n",
        "\n",
        "    # Print results per class\n",
        "    if (verbose or (nc < 50 and not training)) and nc > 1 and len(stats):\n",
        "        for i, c in enumerate(ap_class):\n",
        "            print(pf % (names[c], seen, nt[c], p[i], r[i], ap50[i], ap[i]))\n",
        "\n",
        "    # Print speeds\n",
        "    t = tuple(x / seen * 1E3 for x in (t0, t1, t0 + t1)) + (imgsz, imgsz, batch_size)  # tuple\n",
        "    if not training:\n",
        "        print('Speed: %.1f/%.1f/%.1f ms inference/NMS/total per %gx%g image at batch-size %g' % t)\n",
        "\n",
        "    # Plots\n",
        "    if plots:\n",
        "        confusion_matrix.plot(save_dir=save_dir, names=list(names.values()))\n",
        "        if wandb_logger and wandb_logger.wandb:\n",
        "            val_batches = [wandb_logger.wandb.Image(str(f), caption=f.name) for f in sorted(save_dir.glob('test*.jpg'))]\n",
        "            wandb_logger.log({\"Validation\": val_batches})\n",
        "    if wandb_images:\n",
        "        wandb_logger.log({\"Bounding Box Debugger/Images\": wandb_images})\n",
        "\n",
        "    # Save JSON\n",
        "    if save_json and len(jdict):\n",
        "        w = Path(weights[0] if isinstance(weights, list) else weights).stem if weights is not None else ''  # weights\n",
        "        anno_json = './coco/annotations/instances_val2017.json'  # annotations json\n",
        "        pred_json = str(save_dir / f\"{w}_predictions.json\")  # predictions json\n",
        "        print('\\nEvaluating pycocotools mAP... saving %s...' % pred_json)\n",
        "        with open(pred_json, 'w') as f:\n",
        "            json.dump(jdict, f)\n",
        "\n",
        "        try:  # https://github.com/cocodataset/cocoapi/blob/master/PythonAPI/pycocoEvalDemo.ipynb\n",
        "            from pycocotools.coco import COCO\n",
        "            from pycocotools.cocoeval import COCOeval\n",
        "\n",
        "            anno = COCO(anno_json)  # init annotations api\n",
        "            pred = anno.loadRes(pred_json)  # init predictions api\n",
        "            eval = COCOeval(anno, pred, 'bbox')\n",
        "            if is_coco:\n",
        "                eval.params.imgIds = [int(Path(x).stem) for x in dataloader.dataset.img_files]  # image IDs to evaluate\n",
        "            eval.evaluate()\n",
        "            eval.accumulate()\n",
        "            eval.summarize()\n",
        "            map, map50 = eval.stats[:2]  # update results (mAP@0.5:0.95, mAP@0.5)\n",
        "        except Exception as e:\n",
        "            print(f'pycocotools unable to run: {e}')\n",
        "\n",
        "    # Return results\n",
        "    model.float()  # for training\n",
        "    if not training:\n",
        "        s = f\"\\n{len(list(save_dir.glob('labels/*.txt')))} labels saved to {save_dir / 'labels'}\" if save_txt else ''\n",
        "        print(f\"Results saved to {save_dir}{s}\")\n",
        "    maps = np.zeros(nc) + map\n",
        "    for i, c in enumerate(ap_class):\n",
        "        maps[c] = ap[i]\n",
        "    return (mp, mr, map50, map, *(loss.cpu() / len(dataloader)).tolist()), maps, t\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser(prog='test.py')\n",
        "    parser.add_argument('--weights', nargs='+', type=str, default='yolov7.pt', help='model.pt path(s)')\n",
        "    parser.add_argument('--data', type=str, default='data/coco.yaml', help='*.data path')\n",
        "    parser.add_argument('--batch-size', type=int, default=32, help='size of each image batch')\n",
        "    parser.add_argument('--img-size', type=int, default=640, help='inference size (pixels)')\n",
        "    parser.add_argument('--conf-thres', type=float, default=0.001, help='object confidence threshold')\n",
        "    parser.add_argument('--iou-thres', type=float, default=0.65, help='IOU threshold for NMS')\n",
        "    parser.add_argument('--task', default='val', help='train, val, test, speed or study')\n",
        "    parser.add_argument('--device', default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')\n",
        "    parser.add_argument('--single-cls', action='store_true', help='treat as single-class dataset')\n",
        "    parser.add_argument('--augment', action='store_true', help='augmented inference')\n",
        "    parser.add_argument('--verbose', action='store_true', help='report mAP by class')\n",
        "    parser.add_argument('--save-txt', action='store_true', help='save results to *.txt')\n",
        "    parser.add_argument('--save-hybrid', action='store_true', help='save label+prediction hybrid results to *.txt')\n",
        "    parser.add_argument('--save-conf', action='store_true', help='save confidences in --save-txt labels')\n",
        "    parser.add_argument('--save-json', action='store_true', help='save a cocoapi-compatible JSON results file')\n",
        "    parser.add_argument('--project', default='runs/test', help='save to project/name')\n",
        "    parser.add_argument('--name', default='exp', help='save to project/name')\n",
        "    parser.add_argument('--exist-ok', action='store_true', help='existing project/name ok, do not increment')\n",
        "    parser.add_argument('--no-trace', action='store_true', help='don`t trace model')\n",
        "    parser.add_argument('--v5-metric', action='store_true', help='assume maximum recall as 1.0 in AP calculation')\n",
        "    opt = parser.parse_args()\n",
        "    opt.save_json |= opt.data.endswith('coco.yaml')\n",
        "    opt.data = check_file(opt.data)  # check file\n",
        "    print(opt)\n",
        "    #check_requirements()\n",
        "\n",
        "    if opt.task in ('train', 'val', 'test'):  # run normally\n",
        "        test(opt.data,\n",
        "             opt.weights,\n",
        "             opt.batch_size,\n",
        "             opt.img_size,\n",
        "             opt.conf_thres,\n",
        "             opt.iou_thres,\n",
        "             opt.save_json,\n",
        "             opt.single_cls,\n",
        "             opt.augment,\n",
        "             opt.verbose,\n",
        "             save_txt=opt.save_txt | opt.save_hybrid,\n",
        "             save_hybrid=opt.save_hybrid,\n",
        "             save_conf=opt.save_conf,\n",
        "             trace=not opt.no_trace,\n",
        "             v5_metric=opt.v5_metric\n",
        "             )\n",
        "\n",
        "    elif opt.task == 'speed':  # speed benchmarks\n",
        "        for w in opt.weights:\n",
        "            test(opt.data, w, opt.batch_size, opt.img_size, 0.25, 0.45, save_json=False, plots=False, v5_metric=opt.v5_metric)\n",
        "\n",
        "    elif opt.task == 'study':  # run over a range of settings and save/plot\n",
        "        # python test.py --task study --data coco.yaml --iou 0.65 --weights yolov7.pt\n",
        "        x = list(range(256, 1536 + 128, 128))  # x axis (image sizes)\n",
        "        for w in opt.weights:\n",
        "            f = f'study_{Path(opt.data).stem}_{Path(w).stem}.txt'  # filename to save to\n",
        "            y = []  # y axis\n",
        "            for i in x:  # img-size\n",
        "                print(f'\\nRunning {f} point {i}...')\n",
        "                r, _, t = test(opt.data, w, opt.batch_size, i, opt.conf_thres, opt.iou_thres, opt.save_json,\n",
        "                               plots=False, v5_metric=opt.v5_metric)\n",
        "                y.append(r + t)  # results and times\n",
        "            np.savetxt(f, y, fmt='%10.4g')  # save\n",
        "        os.system('zip -r study.zip study_*.txt')\n",
        "        plot_study_txt(x=x)  # plot\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_s6ygCpi2CO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  - *E3* - Testing the models crossing datasets. Here you must do exactly the same as in *E2*, but now training in one city and testing in the other. **The model trained in location A must be tested in location B. The model trained in location B must be tested in location A.** Use the same metrics and plot the same types of graphs so that results are comparable.\n",
        "\n",
        "[top](scrollTo=4i5afvUbhmGo)"
      ],
      "metadata": {
        "id": "bZ0zVXjQ1x0_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your codes for E3 here. Create more code cells if needed\n",
        "\n",
        "\n",
        "import argparse\n",
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "from threading import Thread\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import yaml\n",
        "from tqdm import tqdm\n",
        "\n",
        "from models.experimental import attempt_load\n",
        "from utils.datasets import create_dataloader\n",
        "from utils.general import coco80_to_coco91_class, check_dataset, check_file, check_img_size, check_requirements, \\\n",
        "    box_iou, non_max_suppression, scale_coords, xyxy2xywh, xywh2xyxy, set_logging, increment_path, colorstr\n",
        "from utils.metrics import ap_per_class, ConfusionMatrix\n",
        "from utils.plots import plot_images, output_to_target, plot_study_txt\n",
        "from utils.torch_utils import select_device, time_synchronized, TracedModel\n",
        "\n",
        "\n",
        "def test(data,\n",
        "         weights=None,\n",
        "         batch_size=32,\n",
        "         imgsz=640,\n",
        "         conf_thres=0.001,\n",
        "         iou_thres=0.6,  # for NMS\n",
        "         save_json=False,\n",
        "         single_cls=False,\n",
        "         augment=False,\n",
        "         verbose=False,\n",
        "         model=None,\n",
        "         dataloader=None,\n",
        "         save_dir=Path(''),  # for saving images\n",
        "         save_txt=False,  # for auto-labelling\n",
        "         save_hybrid=False,  # for hybrid auto-labelling\n",
        "         save_conf=False,  # save auto-label confidences\n",
        "         plots=True,\n",
        "         wandb_logger=None,\n",
        "         compute_loss=None,\n",
        "         half_precision=True,\n",
        "         trace=False,\n",
        "         is_coco=False,\n",
        "         v5_metric=False):\n",
        "    # Initialize/load model and set device\n",
        "    training = model is not None\n",
        "    if training:  # called by train.py\n",
        "        device = next(model.parameters()).device  # get model device\n",
        "\n",
        "    else:  # called directly\n",
        "        set_logging()\n",
        "        device = select_device(opt.device, batch_size=batch_size)\n",
        "\n",
        "        # Directories\n",
        "        save_dir = Path(increment_path(Path(opt.project) / opt.name, exist_ok=opt.exist_ok))  # increment run\n",
        "        (save_dir / 'labels' if save_txt else save_dir).mkdir(parents=True, exist_ok=True)  # make dir\n",
        "\n",
        "        # Load model\n",
        "        model = attempt_load(weights, map_location=device)  # load FP32 model\n",
        "        gs = max(int(model.stride.max()), 32)  # grid size (max stride)\n",
        "        imgsz = check_img_size(imgsz, s=gs)  # check img_size\n",
        "\n",
        "        if trace:\n",
        "            model = TracedModel(model, device, imgsz)\n",
        "\n",
        "    # Half\n",
        "    half = device.type != 'cpu' and half_precision  # half precision only supported on CUDA\n",
        "    if half:\n",
        "        model.half()\n",
        "\n",
        "    # Configure\n",
        "    model.eval()\n",
        "    if isinstance(data, str):\n",
        "        is_coco = data.endswith('coco.yaml')\n",
        "        with open(data) as f:\n",
        "            data = yaml.load(f, Loader=yaml.SafeLoader)\n",
        "    check_dataset(data)  # check\n",
        "    nc = 1 if single_cls else int(data['nc'])  # number of classes\n",
        "    iouv = torch.linspace(0.5, 0.95, 10).to(device)  # iou vector for mAP@0.5:0.95\n",
        "    niou = iouv.numel()\n",
        "\n",
        "    # Logging\n",
        "    log_imgs = 0\n",
        "    if wandb_logger and wandb_logger.wandb:\n",
        "        log_imgs = min(wandb_logger.log_imgs, 100)\n",
        "    # Dataloader\n",
        "    if not training:\n",
        "        if device.type != 'cpu':\n",
        "            model(torch.zeros(1, 3, imgsz, imgsz).to(device).type_as(next(model.parameters())))  # run once\n",
        "        task = opt.task if opt.task in ('train', 'val', 'test') else 'val'  # path to train/val/test images\n",
        "        dataloader = create_dataloader(data[task], imgsz, batch_size, gs, opt, pad=0.5, rect=True,\n",
        "                                       prefix=colorstr(f'{task}: '))[0]\n",
        "\n",
        "    if v5_metric:\n",
        "        print(\"Testing with YOLOv5 AP metric...\")\n",
        "\n",
        "    seen = 0\n",
        "    confusion_matrix = ConfusionMatrix(nc=nc)\n",
        "    names = {k: v for k, v in enumerate(model.names if hasattr(model, 'names') else model.module.names)}\n",
        "    coco91class = coco80_to_coco91_class()\n",
        "    s = ('%20s' + '%12s' * 6) % ('Class', 'Images', 'Labels', 'P', 'R', 'mAP@.5', 'mAP@.5:.95')\n",
        "    p, r, f1, mp, mr, map50, map, t0, t1 = 0., 0., 0., 0., 0., 0., 0., 0., 0.\n",
        "    loss = torch.zeros(3, device=device)\n",
        "    jdict, stats, ap, ap_class, wandb_images = [], [], [], [], []\n",
        "    for batch_i, (img, targets, paths, shapes) in enumerate(tqdm(dataloader, desc=s)):\n",
        "        img = img.to(device, non_blocking=True)\n",
        "        img = img.half() if half else img.float()  # uint8 to fp16/32\n",
        "        img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
        "        targets = targets.to(device)\n",
        "        nb, _, height, width = img.shape  # batch size, channels, height, width\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # Run model\n",
        "            t = time_synchronized()\n",
        "            out, train_out = model(img, augment=augment)  # inference and training outputs\n",
        "            t0 += time_synchronized() - t\n",
        "\n",
        "            # Compute loss\n",
        "            if compute_loss:\n",
        "                loss += compute_loss([x.float() for x in train_out], targets)[1][:3]  # box, obj, cls\n",
        "\n",
        "            # Run NMS\n",
        "            targets[:, 2:] *= torch.Tensor([width, height, width, height]).to(device)  # to pixels\n",
        "            lb = [targets[targets[:, 0] == i, 1:] for i in range(nb)] if save_hybrid else []  # for autolabelling\n",
        "            t = time_synchronized()\n",
        "            out = non_max_suppression(out, conf_thres=conf_thres, iou_thres=iou_thres, labels=lb, multi_label=True)\n",
        "            t1 += time_synchronized() - t\n",
        "\n",
        "        # Statistics per image\n",
        "        for si, pred in enumerate(out):\n",
        "            labels = targets[targets[:, 0] == si, 1:]\n",
        "            nl = len(labels)\n",
        "            tcls = labels[:, 0].tolist() if nl else []  # target class\n",
        "            path = Path(paths[si])\n",
        "            seen += 1\n",
        "\n",
        "            if len(pred) == 0:\n",
        "                if nl:\n",
        "                    stats.append((torch.zeros(0, niou, dtype=torch.bool), torch.Tensor(), torch.Tensor(), tcls))\n",
        "                continue\n",
        "\n",
        "            # Predictions\n",
        "            predn = pred.clone()\n",
        "            scale_coords(img[si].shape[1:], predn[:, :4], shapes[si][0], shapes[si][1])  # native-space pred\n",
        "\n",
        "            # Append to text file\n",
        "            if save_txt:\n",
        "                gn = torch.tensor(shapes[si][0])[[1, 0, 1, 0]]  # normalization gain whwh\n",
        "                for *xyxy, conf, cls in predn.tolist():\n",
        "                    xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh\n",
        "                    line = (cls, *xywh, conf) if save_conf else (cls, *xywh)  # label format\n",
        "                    with open(save_dir / 'labels' / (path.stem + '.txt'), 'a') as f:\n",
        "                        f.write(('%g ' * len(line)).rstrip() % line + '\\n')\n",
        "\n",
        "            # W&B logging - Media Panel Plots\n",
        "            if len(wandb_images) < log_imgs and wandb_logger.current_epoch > 0:  # Check for test operation\n",
        "                if wandb_logger.current_epoch % wandb_logger.bbox_interval == 0:\n",
        "                    box_data = [{\"position\": {\"minX\": xyxy[0], \"minY\": xyxy[1], \"maxX\": xyxy[2], \"maxY\": xyxy[3]},\n",
        "                                 \"class_id\": int(cls),\n",
        "                                 \"box_caption\": \"%s %.3f\" % (names[cls], conf),\n",
        "                                 \"scores\": {\"class_score\": conf},\n",
        "                                 \"domain\": \"pixel\"} for *xyxy, conf, cls in pred.tolist()]\n",
        "                    boxes = {\"predictions\": {\"box_data\": box_data, \"class_labels\": names}}  # inference-space\n",
        "                    wandb_images.append(wandb_logger.wandb.Image(img[si], boxes=boxes, caption=path.name))\n",
        "            wandb_logger.log_training_progress(predn, path, names) if wandb_logger and wandb_logger.wandb_run else None\n",
        "\n",
        "            # Append to pycocotools JSON dictionary\n",
        "            if save_json:\n",
        "                # [{\"image_id\": 42, \"category_id\": 18, \"bbox\": [258.15, 41.29, 348.26, 243.78], \"score\": 0.236}, ...\n",
        "                image_id = int(path.stem) if path.stem.isnumeric() else path.stem\n",
        "                box = xyxy2xywh(predn[:, :4])  # xywh\n",
        "                box[:, :2] -= box[:, 2:] / 2  # xy center to top-left corner\n",
        "                for p, b in zip(pred.tolist(), box.tolist()):\n",
        "                    jdict.append({'image_id': image_id,\n",
        "                                  'category_id': coco91class[int(p[5])] if is_coco else int(p[5]),\n",
        "                                  'bbox': [round(x, 3) for x in b],\n",
        "                                  'score': round(p[4], 5)})\n",
        "\n",
        "            # Assign all predictions as incorrect\n",
        "            correct = torch.zeros(pred.shape[0], niou, dtype=torch.bool, device=device)\n",
        "            if nl:\n",
        "                detected = []  # target indices\n",
        "                tcls_tensor = labels[:, 0]\n",
        "\n",
        "                # target boxes\n",
        "                tbox = xywh2xyxy(labels[:, 1:5])\n",
        "                scale_coords(img[si].shape[1:], tbox, shapes[si][0], shapes[si][1])  # native-space labels\n",
        "                if plots:\n",
        "                    confusion_matrix.process_batch(predn, torch.cat((labels[:, 0:1], tbox), 1))\n",
        "\n",
        "                # Per target class\n",
        "                for cls in torch.unique(tcls_tensor):\n",
        "                    ti = (cls == tcls_tensor).nonzero(as_tuple=False).view(-1)  # prediction indices\n",
        "                    pi = (cls == pred[:, 5]).nonzero(as_tuple=False).view(-1)  # target indices\n",
        "\n",
        "                    # Search for detections\n",
        "                    if pi.shape[0]:\n",
        "                        # Prediction to target ious\n",
        "                        ious, i = box_iou(predn[pi, :4], tbox[ti]).max(1)  # best ious, indices\n",
        "\n",
        "                        # Append detections\n",
        "                        detected_set = set()\n",
        "                        for j in (ious > iouv[0]).nonzero(as_tuple=False):\n",
        "                            d = ti[i[j]]  # detected target\n",
        "                            if d.item() not in detected_set:\n",
        "                                detected_set.add(d.item())\n",
        "                                detected.append(d)\n",
        "                                correct[pi[j]] = ious[j] > iouv  # iou_thres is 1xn\n",
        "                                if len(detected) == nl:  # all targets already located in image\n",
        "                                    break\n",
        "\n",
        "            # Append statistics (correct, conf, pcls, tcls)\n",
        "            stats.append((correct.cpu(), pred[:, 4].cpu(), pred[:, 5].cpu(), tcls))\n",
        "\n",
        "        # Plot images\n",
        "        if plots and batch_i < 3:\n",
        "            f = save_dir / f'test_batch{batch_i}_labels.jpg'  # labels\n",
        "            Thread(target=plot_images, args=(img, targets, paths, f, names), daemon=True).start()\n",
        "            f = save_dir / f'test_batch{batch_i}_pred.jpg'  # predictions\n",
        "            Thread(target=plot_images, args=(img, output_to_target(out), paths, f, names), daemon=True).start()\n",
        "\n",
        "    # Compute statistics\n",
        "    stats = [np.concatenate(x, 0) for x in zip(*stats)]  # to numpy\n",
        "    if len(stats) and stats[0].any():\n",
        "        p, r, ap, f1, ap_class = ap_per_class(*stats, plot=plots, v5_metric=v5_metric, save_dir=save_dir, names=names)\n",
        "        ap50, ap = ap[:, 0], ap.mean(1)  # AP@0.5, AP@0.5:0.95\n",
        "        mp, mr, map50, map = p.mean(), r.mean(), ap50.mean(), ap.mean()\n",
        "        nt = np.bincount(stats[3].astype(np.int64), minlength=nc)  # number of targets per class\n",
        "    else:\n",
        "        nt = torch.zeros(1)\n",
        "\n",
        "    # Print results\n",
        "    pf = '%20s' + '%12i' * 2 + '%12.3g' * 4  # print format\n",
        "    print(pf % ('all', seen, nt.sum(), mp, mr, map50, map))\n",
        "\n",
        "    # Print results per class\n",
        "    if (verbose or (nc < 50 and not training)) and nc > 1 and len(stats):\n",
        "        for i, c in enumerate(ap_class):\n",
        "            print(pf % (names[c], seen, nt[c], p[i], r[i], ap50[i], ap[i]))\n",
        "\n",
        "    # Print speeds\n",
        "    t = tuple(x / seen * 1E3 for x in (t0, t1, t0 + t1)) + (imgsz, imgsz, batch_size)  # tuple\n",
        "    if not training:\n",
        "        print('Speed: %.1f/%.1f/%.1f ms inference/NMS/total per %gx%g image at batch-size %g' % t)\n",
        "\n",
        "    # Plots\n",
        "    if plots:\n",
        "        confusion_matrix.plot(save_dir=save_dir, names=list(names.values()))\n",
        "        if wandb_logger and wandb_logger.wandb:\n",
        "            val_batches = [wandb_logger.wandb.Image(str(f), caption=f.name) for f in sorted(save_dir.glob('test*.jpg'))]\n",
        "            wandb_logger.log({\"Validation\": val_batches})\n",
        "    if wandb_images:\n",
        "        wandb_logger.log({\"Bounding Box Debugger/Images\": wandb_images})\n",
        "\n",
        "    # Save JSON\n",
        "    if save_json and len(jdict):\n",
        "        w = Path(weights[0] if isinstance(weights, list) else weights).stem if weights is not None else ''  # weights\n",
        "        anno_json = './coco/annotations/instances_val2017.json'  # annotations json\n",
        "        pred_json = str(save_dir / f\"{w}_predictions.json\")  # predictions json\n",
        "        print('\\nEvaluating pycocotools mAP... saving %s...' % pred_json)\n",
        "        with open(pred_json, 'w') as f:\n",
        "            json.dump(jdict, f)\n",
        "\n",
        "        try:  # https://github.com/cocodataset/cocoapi/blob/master/PythonAPI/pycocoEvalDemo.ipynb\n",
        "            from pycocotools.coco import COCO\n",
        "            from pycocotools.cocoeval import COCOeval\n",
        "\n",
        "            anno = COCO(anno_json)  # init annotations api\n",
        "            pred = anno.loadRes(pred_json)  # init predictions api\n",
        "            eval = COCOeval(anno, pred, 'bbox')\n",
        "            if is_coco:\n",
        "                eval.params.imgIds = [int(Path(x).stem) for x in dataloader.dataset.img_files]  # image IDs to evaluate\n",
        "            eval.evaluate()\n",
        "            eval.accumulate()\n",
        "            eval.summarize()\n",
        "            map, map50 = eval.stats[:2]  # update results (mAP@0.5:0.95, mAP@0.5)\n",
        "        except Exception as e:\n",
        "            print(f'pycocotools unable to run: {e}')\n",
        "\n",
        "    # Return results\n",
        "    model.float()  # for training\n",
        "    if not training:\n",
        "        s = f\"\\n{len(list(save_dir.glob('labels/*.txt')))} labels saved to {save_dir / 'labels'}\" if save_txt else ''\n",
        "        print(f\"Results saved to {save_dir}{s}\")\n",
        "    maps = np.zeros(nc) + map\n",
        "    for i, c in enumerate(ap_class):\n",
        "        maps[c] = ap[i]\n",
        "    return (mp, mr, map50, map, *(loss.cpu() / len(dataloader)).tolist()), maps, t\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser(prog='test.py')\n",
        "    parser.add_argument('--weights', nargs='+', type=str, default='yolov7.pt', help='model.pt path(s)')\n",
        "    parser.add_argument('--data', type=str, default='data/coco.yaml', help='*.data path')\n",
        "    parser.add_argument('--batch-size', type=int, default=32, help='size of each image batch')\n",
        "    parser.add_argument('--img-size', type=int, default=640, help='inference size (pixels)')\n",
        "    parser.add_argument('--conf-thres', type=float, default=0.001, help='object confidence threshold')\n",
        "    parser.add_argument('--iou-thres', type=float, default=0.65, help='IOU threshold for NMS')\n",
        "    parser.add_argument('--task', default='val', help='train, val, test, speed or study')\n",
        "    parser.add_argument('--device', default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')\n",
        "    parser.add_argument('--single-cls', action='store_true', help='treat as single-class dataset')\n",
        "    parser.add_argument('--augment', action='store_true', help='augmented inference')\n",
        "    parser.add_argument('--verbose', action='store_true', help='report mAP by class')\n",
        "    parser.add_argument('--save-txt', action='store_true', help='save results to *.txt')\n",
        "    parser.add_argument('--save-hybrid', action='store_true', help='save label+prediction hybrid results to *.txt')\n",
        "    parser.add_argument('--save-conf', action='store_true', help='save confidences in --save-txt labels')\n",
        "    parser.add_argument('--save-json', action='store_true', help='save a cocoapi-compatible JSON results file')\n",
        "    parser.add_argument('--project', default='runs/test', help='save to project/name')\n",
        "    parser.add_argument('--name', default='exp', help='save to project/name')\n",
        "    parser.add_argument('--exist-ok', action='store_true', help='existing project/name ok, do not increment')\n",
        "    parser.add_argument('--no-trace', action='store_true', help='don`t trace model')\n",
        "    parser.add_argument('--v5-metric', action='store_true', help='assume maximum recall as 1.0 in AP calculation')\n",
        "    opt = parser.parse_args()\n",
        "    opt.save_json |= opt.data.endswith('coco.yaml')\n",
        "    opt.data = check_file(opt.data)  # check file\n",
        "    print(opt)\n",
        "    #check_requirements()\n",
        "\n",
        "    if opt.task in ('train', 'val', 'test'):  # run normally\n",
        "        test(opt.data,\n",
        "             opt.weights,\n",
        "             opt.batch_size,\n",
        "             opt.img_size,\n",
        "             opt.conf_thres,\n",
        "             opt.iou_thres,\n",
        "             opt.save_json,\n",
        "             opt.single_cls,\n",
        "             opt.augment,\n",
        "             opt.verbose,\n",
        "             save_txt=opt.save_txt | opt.save_hybrid,\n",
        "             save_hybrid=opt.save_hybrid,\n",
        "             save_conf=opt.save_conf,\n",
        "             trace=not opt.no_trace,\n",
        "             v5_metric=opt.v5_metric\n",
        "             )\n",
        "\n",
        "    elif opt.task == 'speed':  # speed benchmarks\n",
        "        for w in opt.weights:\n",
        "            test(opt.data, w, opt.batch_size, opt.img_size, 0.25, 0.45, save_json=False, plots=False, v5_metric=opt.v5_metric)\n",
        "\n",
        "    elif opt.task == 'study':  # run over a range of settings and save/plot\n",
        "        # python test.py --task study --data coco.yaml --iou 0.65 --weights yolov7.pt\n",
        "        x = list(range(256, 1536 + 128, 128))  # x axis (image sizes)\n",
        "        for w in opt.weights:\n",
        "            f = f'study_{Path(opt.data).stem}_{Path(w).stem}.txt'  # filename to save to\n",
        "            y = []  # y axis\n",
        "            for i in x:  # img-size\n",
        "                print(f'\\nRunning {f} point {i}...')\n",
        "                r, _, t = test(opt.data, w, opt.batch_size, i, opt.conf_thres, opt.iou_thres, opt.save_json,\n",
        "                               plots=False, v5_metric=opt.v5_metric)\n",
        "                y.append(r + t)  # results and times\n",
        "            np.savetxt(f, y, fmt='%10.4g')  # save\n",
        "        os.system('zip -r study.zip study_*.txt')\n",
        "        plot_study_txt(x=x)  # plot\n",
        "\n"
      ],
      "metadata": {
        "id": "Cotguzxyo3Sa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# 7. **Quiz and Report**\n",
        "\n",
        "Answer the assessment quiz that will be made available on Canvas one week before the final deadline. Make a 2-page latex report using the [IEEE template](https://www.overleaf.com/read/hkfsjjsxmxcn) with a maximum of 1000 words. You can deliver the report in MS Word if you prefer. Your report should contain five sections: introduction, description of the proposed solution with justifications, results (here you can include the same graphs and pictures generated in this jupyter notebook), discussion of the results, and conclusion. Properly cite references to articles, tutorials, and sources used. A pdf version of your report should be made available in the project's github repository under the name \"[project name] + _final_report.pdf\".\n",
        "\n",
        "\n",
        "[top](#scrollTo=4i5afvUbhmGo)"
      ],
      "metadata": {
        "id": "ws14iV4Dp_vf"
      }
    }
  ]
}